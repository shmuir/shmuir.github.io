{
  "hash": "a6c3b32a32ca53f961ad0df98ea6f7f0",
  "result": {
    "markdown": "---\ntitle: \"Who's on AUX? Using machine learning to predict whose Spotify playlist a song belongs to\"\ndescription: \"Building my ML skills through a fun musical project\"\nauthor:\n  - name: Sam Muir\n    url: https://shmuir.github.io/\n  #  orcid: \n    affiliation: Bren School of Environmental Science & Management at University of California Santa Barbara\n    affiliation-url: https://bren.ucsb.edu/masters-programs/master-environmental-data-science\ndate: 04-13-2024\ncategories: [ML, R, MEDS]\nbibliography: references.bib\ncitation:\n  url: https://shmuir.github.io/projects/2024-04-13-spotify-predictions/\nimage: spotify.jpeg\nformat:\n  html:\n    code-fold: false\ndraft: false\n---\n\n\n\n\n\n\n# Project Overview\n\nIn this project, I am interested in building my machine learning skills through a fun exercise with Spotify! \n\nUsing my liked songs and my friends, can I build a machine learning model to predict whose playlist a song belongs to? \n\n# Data & Methods\n\nFor this project, I will be requesting data from the Spotify API using the `{spotifyr}` package and using the data to build k-nearest neighbor and decision tree models. \n\n## Data Preparation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSys.setenv(SPOTIFY_CLIENT_ID = SPOTIFY_CLIENT_ID)\nSys.setenv(SPOTIFY_CLIENT_SECRET = SPOTIFY_CLIENT_SECRET)\n\nauthorization_code <- get_spotify_authorization_code(scope = scopes()[c(1:19)]) #sets an authorization code that you'll need to provide for certain get_ functions via my_tracks <- get_my_saved_tracks(authorization = authorization_code)\n\naccess_token <- get_spotify_access_token() #takes ID and SECRET, sends to Spotify and receives an access token\n```\n:::\n\n\nUsing `get_my_saved_tracks()`, the Spotify API returns a dataframe of tracks and associated attributes. However, it will only return up to 50 tracks at a time, so I will need to make multiple requests. To do this, I will use a function to combine all the requests in one call.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\noffsets = seq(from = 0, to = 150, by = 50)\n\n#initializing an empty df\nmy_tracks <- data.frame(matrix(nrow = 0, ncol = 30))\n\n# function to get my 150 most recently liked tracks\nfor (i in seq_along(offsets)) {\n  liked_tracks = get_my_saved_tracks(authorization = authorization_code, limit = 50,\n                                     offset = offsets[i])\n  df_temp = as.data.frame(liked_tracks) # creating a temporary data frame\n  my_tracks <- rbind(my_tracks, df_temp) # binding the temporary data frame to my tracks data frame\n}\n```\n:::\n\n\nAdditionally, by giving the API a list of track IDs using get_track_audio_features(), I can get an audio features dataframe of all the tracks and some attributes of them.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naudio1 <- get_track_audio_features(my_tracks$track.id[1:100])\naudio2 <- get_track_audio_features(my_tracks$track.id[101:200])\n\naudio_features <- rbind(audio1, audio2)\n```\n:::\n\n\nThese track audio features are the predictors we are interested in, but this dataframe doesn't have the actual names of the tracks, so I need to append the 'track.name' column from my favorite tracks dataframe.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsam_audio <- my_tracks %>%\n  select(track.name) %>%\n  bind_cols(audio_features) %>%\n  mutate(name = \"sam\")\n```\n:::\n\n\nOne of my friends followed these same steps, and she sent me a .csv of her track audio features, which I will bind with my audio features dataframe.\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# read in anna audio\nanna_audio <- read_csv(here::here(\"projects/2024-04-13-spotify-predictions/named_audio_anna.csv\")) %>%\n  mutate(name = \"anna\")\n\n# bind mine and anna's data \nboth_audio <- rbind(sam_audio, anna_audio)\n```\n:::\n\n\n\n## Data Exploration\n\nNow that the data is ready to go, let's do a little data exploration. There are a lot of cool audio features to explore. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(both_audio, aes(x = danceability, fill = name)) +\n  geom_density(alpha=0.5) +\n  scale_fill_manual(values=c(\"magenta4\", \"seagreen\"))+\n  labs(x=\"Danceability\", y=\"Density\", title = \"Distribution of Music Danceability Data\") +\n  guides(fill=guide_legend(title=\"Listener\")) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(both_audio, aes(x = energy, fill = name)) +\n  geom_density(alpha=0.6) +\n  scale_fill_manual(values=c(\"magenta4\", \"seagreen\"))+\n  labs(x=\"Energy\", y=\"Density\", title = \"Distribution of Music Energy Data\") +\n  guides(fill=guide_legend(title=\"Listener\")) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n\n```{.r .cell-code}\nrbind(anna_audio[which.max(anna_audio$danceability),],\n      sam_audio[which.max(sam_audio$danceability),]) %>%\n  select(track.name, danceability, name) %>%\n  gt::gt(caption = \"Liked tracks with the highest danceability\")\n```\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"mhijdbxnqn\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#mhijdbxnqn table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#mhijdbxnqn thead, #mhijdbxnqn tbody, #mhijdbxnqn tfoot, #mhijdbxnqn tr, #mhijdbxnqn td, #mhijdbxnqn th {\n  border-style: none;\n}\n\n#mhijdbxnqn p {\n  margin: 0;\n  padding: 0;\n}\n\n#mhijdbxnqn .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#mhijdbxnqn .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#mhijdbxnqn .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#mhijdbxnqn .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#mhijdbxnqn .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#mhijdbxnqn .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#mhijdbxnqn .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#mhijdbxnqn .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#mhijdbxnqn .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#mhijdbxnqn .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#mhijdbxnqn .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#mhijdbxnqn .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#mhijdbxnqn .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#mhijdbxnqn .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#mhijdbxnqn .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#mhijdbxnqn .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#mhijdbxnqn .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#mhijdbxnqn .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#mhijdbxnqn .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#mhijdbxnqn .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#mhijdbxnqn .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#mhijdbxnqn .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#mhijdbxnqn .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#mhijdbxnqn .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#mhijdbxnqn .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#mhijdbxnqn .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#mhijdbxnqn .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#mhijdbxnqn .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#mhijdbxnqn .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#mhijdbxnqn .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#mhijdbxnqn .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#mhijdbxnqn .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#mhijdbxnqn .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#mhijdbxnqn .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#mhijdbxnqn .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#mhijdbxnqn .gt_left {\n  text-align: left;\n}\n\n#mhijdbxnqn .gt_center {\n  text-align: center;\n}\n\n#mhijdbxnqn .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#mhijdbxnqn .gt_font_normal {\n  font-weight: normal;\n}\n\n#mhijdbxnqn .gt_font_bold {\n  font-weight: bold;\n}\n\n#mhijdbxnqn .gt_font_italic {\n  font-style: italic;\n}\n\n#mhijdbxnqn .gt_super {\n  font-size: 65%;\n}\n\n#mhijdbxnqn .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#mhijdbxnqn .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#mhijdbxnqn .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#mhijdbxnqn .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#mhijdbxnqn .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#mhijdbxnqn .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#mhijdbxnqn .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <caption>Liked tracks with the highest danceability</caption>\n  <thead>\n    \n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"track.name\">track.name</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"danceability\">danceability</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"name\">name</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"track.name\" class=\"gt_row gt_left\">Chilling At Nemu's Place</td>\n<td headers=\"danceability\" class=\"gt_row gt_right\">0.943</td>\n<td headers=\"name\" class=\"gt_row gt_left\">anna</td></tr>\n    <tr><td headers=\"track.name\" class=\"gt_row gt_left\">Als ich ein Kind war</td>\n<td headers=\"danceability\" class=\"gt_row gt_right\">0.948</td>\n<td headers=\"name\" class=\"gt_row gt_left\">sam</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n\n\n# Building Machine Learning Models\n\n## Modeling Prep\n\nFurther preparation is needed before running the models. First, I need to remove unnecessary columns including track urls and the track name. Next I'll split the data into training and testing sets, using a 75:25 split. Finally, I'll create my recipe, normalizing the nominal and numeric predictors and prep. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# prepare data ----\nall_tracks_modeling <- both_audio %>%  \n  mutate_if(is.ordered, .funs = factor, ordered = F) %>%\n  select(-track.name, -type, -id, -uri, -track_href, -analysis_url) %>%\n  mutate(name = as.factor(name))\n\n# splitting the data ----\nset.seed(123)\n\ntracks_split <- initial_split(all_tracks_modeling, prop = 0.75)\ntracks_train <- training(tracks_split)\ntracks_test <- testing(tracks_split)\n\n# create a recipe ----\ntracks_recipe <- recipe(name ~ ., data = tracks_train) %>%\n  step_dummy(all_nominal_predictors()) %>%\n  step_normalize(all_numeric_predictors()) %>% #normalize numeric to make sure scale is okay\n  prep()\n```\n:::\n\n\n## K-Nearest Neighbor\n\nThe first model I want to build uses k-nearest neighbor. This is a classification problem (classifying the track as either belonging to my liked songs or my friends liked songs), so I will `set_mode()` to \"classification\" and `set_engine()` to \"kknn\".  \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define our KNN model with tuning ----\nknn_spec_tune <- nearest_neighbor(neighbor = tune()) %>%\n  set_mode(\"classification\") %>%\n  set_engine(\"kknn\")\n\n# Check the model\n#knn_spec_tune\n```\n:::\n\n\nNext I need to define my workflow by adding the model and recipe I defined above. \n\n::: {.cell}\n\n```{.r .cell-code}\n# Define a new workflow ----\nwf_knn_tune <- workflow() %>%\n  add_model(knn_spec_tune) %>%\n  add_recipe(tracks_recipe)\n```\n:::\n\n\nTo hopefully increase the accuracy of my model, I will use 10 fold cross validation to further split and train on my data. \n\n::: {.cell}\n\n```{.r .cell-code}\n# 10-fold CV on the training dataset ----\nset.seed(123)\n\ncv_folds <- tracks_train %>%\n  vfold_cv(v = 10)\n```\n:::\n\n\nNow that everything is ready to go, I can fit the workflow on the folds and check out the parameter tuning.  \n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit the workflow on our predefined folds and hyperparameters ----\nfit_knn_cv <- wf_knn_tune %>%\n  tune_grid(resamples = cv_folds,\n            grid = 10)\n    \n# Check the performance with collect_metrics()\n#collect_metrics(fit_knn_cv)\n\n# plot cv results for parameter tuning ----\nautoplot(fit_knn_cv) + \n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nUsing the fit workflow, I can finalize and select the best iteration based on the ROC AUC and predict on the training and testing data. \n\n::: {.cell}\n\n```{.r .cell-code}\n# The final workflow for our KNN model ----\nfinal_knn_wf <- wf_knn_tune %>%\n  finalize_workflow(select_best(fit_knn_cv, metric = \"roc_auc\"))\n\ntrain_knn_fit <- fit(final_knn_wf, tracks_train)\n\ntrain_predict <- predict(object = train_knn_fit, new_data = tracks_train) %>% #predict the training set\n  bind_cols(tracks_train) #bind training set column to prediction\n\ntest_knn_predict <- predict(train_knn_fit, tracks_test) %>% #get prediction probabilities for test \n  bind_cols(tracks_test) %>%  #bind to testing column\n  mutate(name = as.factor(name))\n```\n:::\n\n\nWith my model now finalized, we can look at the accuracy of the training predictions compared to the testing predictions. \n\n::: {.cell}\n\n```{.r .cell-code}\n# report the accuracy for the training and testing ----\naccuracy(train_predict, truth = name, estimate = .pred_class) #get training accuracy\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.823\n```\n:::\n\n```{.r .cell-code}\naccuracy(test_knn_predict, truth = name, estimate = .pred_class) #get accuracy of testing prediction\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary          0.63\n```\n:::\n:::\n\n\nHere is the optimized workflow for the KNN model along with the result metrics. \n\n::: {.cell}\n\n```{.r .cell-code}\n# Optimizing workflow ----\nfinal_knn_fit <- final_knn_wf %>% \n  last_fit(tracks_split)\n\n# last_fit() fit on the training data but then also evaluates on the testing data\nfinal_knn_result <- last_fit(final_knn_wf, tracks_split)\n\n# testing predictions and metrics ----\n#final_knn_result$.predictions \nknn_predict_data <- as.data.frame(final_knn_result$.predictions) %>%\n  bind_cols(tracks_test)\n\nfinal_knn_result$.metrics\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.63  Preprocessor1_Model1\n2 roc_auc  binary         0.661 Preprocessor1_Model1\n```\n:::\n:::\n\n\n### Decision Tree\n\nLet's build another model! This time I am going to be building a decision tree and tuning model hyperparameters. The hyperparameters I have chosen to tune are cost complexity, tree depth, and the minimum number of data points in a node. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n#new spec, tell the model that we are tuning hyperparams ----\ntree_spec_tune <- decision_tree(\n  cost_complexity = tune(),\n  tree_depth = tune(),\n  min_n = tune()\n) %>%\n  set_engine(\"rpart\") %>%\n  set_mode(\"classification\")\n\ntree_grid <- grid_regular(cost_complexity(), tree_depth(), min_n(), levels = 5)\n#head(tree_grid)\n```\n:::\n\n\nNow I can define a new workflow and set up the k-folds\n\n::: {.cell}\n\n```{.r .cell-code}\n# setting up the workflow ----\nwf_tree_tune <- workflow() %>%\n  add_recipe(tracks_recipe) %>%\n  add_model(tree_spec_tune)\n\n# set up k-fold cv ----\ntracks_cv <- tracks_train %>%\n  vfold_cv(v=10)\n#tracks_cv\n```\n:::\n\n\nSince the decision tree is more computationally expensive, I am going to be using parallel processing to help with grid tuning computation time. \n\n::: {.cell}\n\n```{.r .cell-code}\n# build trees ----\ndoParallel::registerDoParallel() #build trees in parallel\ntree_rs <- tune_grid(\n  wf_tree_tune,\n  resamples = tracks_cv,\n  grid = tree_grid,\n  metrics = metric_set(accuracy)\n)\n\n# Use autoplot() to examine how different parameter configurations relate to accuracy ----\nautoplot(tree_rs) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\nWith the grid tuning finished I can select the best hyperparameters, finalize the workflow, fit the data, and make predictions on the testing data. \n\n::: {.cell}\n\n```{.r .cell-code}\n# select hyperparameter ----\n#show_best(tree_rs) # showing\nselect_best(tree_rs) # what we'll input\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 4\n  cost_complexity tree_depth min_n .config               \n            <dbl>      <int> <int> <chr>                 \n1    0.0000000001          4    30 Preprocessor1_Model081\n```\n:::\n\n```{.r .cell-code}\n# finalize the model specification where we have replaced the tune functions with optimized values ----\nfinal_tree <- finalize_workflow(wf_tree_tune, select_best(tree_rs))\n#final_tree\n\n# final fitting ----\nfinal_tree_fit <- fit(final_tree, data = tracks_train) \n\n# last_fit() fit on the training data but then also evaluates on the testing data\nfinal_tree_result <- last_fit(final_tree, tracks_split)\n\n# testing predictions and metrics ----\n#final_tree_result$.predictions \nfinal_tree_result$.metrics\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.65  Preprocessor1_Model1\n2 roc_auc  binary         0.626 Preprocessor1_Model1\n```\n:::\n\n```{.r .cell-code}\npredict_tree_data <- predict(final_tree_fit, tracks_test) %>% #get prediction probabilities for test \n  bind_cols(tracks_test) %>%  #bind to testing column\n  mutate(name = as.factor(name))\n\n#Visualize variable importance ----\nfinal_tree_fit %>%\n  vip(geom = \"point\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n## Bagged Tree\n\n\nThe third model I am going to build is a bagged tree model where I tune the cost complexity and the minimum number of data points in a node. \n\n::: {.cell}\n\n```{.r .cell-code}\n# set up the bagged tree model ----\nbagged_tree <- bag_tree(\n  cost_complexity = tune(),\n  min_n = tune()\n) %>%\n  set_engine(\"rpart\", times = 50) %>%\n  set_mode(\"classification\")\n```\n:::\n\n\nSetting up the workflow and grid tuning. \n\n::: {.cell}\n\n```{.r .cell-code}\n# workflow ----\nwf_bag_tune <- workflow() %>%\n  add_recipe(tracks_recipe) %>%\n  add_model(bagged_tree)\n\n# set up the tuning ----\nbag_grid <- grid_regular(cost_complexity(), min_n(), levels = 5)\n\nbag_rs <- tune_grid(\n  wf_bag_tune,\n  resamples = tracks_cv,\n  grid = bag_grid,\n  metrics = metric_set(accuracy))\n```\n:::\n\n\nSelect the best hyperparameters, finalize the workflow, fit, and predict. \n\n::: {.cell}\n\n```{.r .cell-code}\n# select hyperparameter ----\n#show_best(bag_rs) # showing\nselect_best(bag_rs) # what we'll input\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  cost_complexity min_n .config              \n            <dbl> <int> <chr>                \n1      0.00000316    11 Preprocessor1_Model08\n```\n:::\n\n```{.r .cell-code}\n# finalize the model specification ----\nfinal_bag <- finalize_workflow(wf_bag_tune, select_best(bag_rs))\n#final_bag\n\n# final fitting ----\nfinal_bag_fit <- fit(final_bag, data = tracks_train) \n\n# last_fit() fit on the training data but then also evaluates on the testing data\nfinal_bag_result <- last_fit(final_bag, tracks_split)\n\n# testing predictions and metrics ----\nbag_data <- predict(final_bag_fit, tracks_test) %>% #get prediction probabilities for test \n  bind_cols(tracks_test) %>%  #bind to testing column\n  mutate(name = as.factor(name))\n\n#final_bag_result$.predictions \n\n# report final metrics ----\nfinal_bag_result$.metrics\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.7   Preprocessor1_Model1\n2 roc_auc  binary         0.756 Preprocessor1_Model1\n```\n:::\n:::\n\n\n## Random Forest\n\nFinally, I am going to be building a random forest model where I tune the number of trees and the number of predictors that will be randomly sampled at each split. \n\n::: {.cell}\n\n```{.r .cell-code}\n# random forest ----\nrf_model <- rand_forest(mtry = tune(),\n                  trees = tune()) %>%\n  set_engine(\"ranger\") %>%\n  set_mode(\"classification\")\n```\n:::\n\n\nContain the model and recipe in a workflow and grid tuning. \n\n::: {.cell}\n\n```{.r .cell-code}\n# workflow ----\nrf_workflow <- workflow() %>%\n  add_model(rf_model) %>%\n  add_recipe(tracks_recipe)\n\n# parameter tuning ----\nrf_cv_tune <- rf_workflow %>%\n  tune_grid(resamples = cv_folds, grid = 10) #use cross validation to tune mtry and trees parameters\n\n#get metrics from tuning cv to pick best model ----\n#collect_metrics(rf_cv_tune) \n\n#plot cv results for parameter tuning ----\nautoplot(rf_cv_tune) + \n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\nFinalize the workflow, fit, and predict. \n\n::: {.cell}\n\n```{.r .cell-code}\n# finalize workflow ----\nrf_best <- show_best(rf_cv_tune, n = 1, metric = \"roc_auc\") #get metrics for best random forest model\nrf_best\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 8\n   mtry trees .metric .estimator  mean     n std_err .config              \n  <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1     4  1889 roc_auc binary     0.732    10  0.0332 Preprocessor1_Model04\n```\n:::\n\n```{.r .cell-code}\nrf_final <- finalize_workflow(rf_workflow,\n                              select_best(rf_cv_tune, metric = \"roc_auc\"))\n\n# model fitting ----\ntrain_fit_rf <- fit(rf_final, tracks_train) #fit the KNN model to the training set\n#train_fit_rf\n\n# prediction probabilities ----\ntest_predict_rf <- predict(train_fit_rf, tracks_test) %>% #get prediction probabilities for test \n  bind_cols(tracks_test) %>%  #bind to testing column\n  mutate(name = as.factor(name))\n\ntest_predict2_rf <- predict(train_fit_rf, tracks_test, type = \"prob\") %>% #get testing prediction\n  bind_cols(tracks_test) %>%  #bind to testing column\n  mutate(name = as.factor(name))\n\n# model metrics and evaluation\n#accuracy(test_predict_rf, truth = name, estimate = .pred_class) #get accuracy of testing prediction\n\nrf_final_result <- last_fit(rf_final, tracks_split)\n\n# testing predictions and metrics ----\n#rf_final_result$.predictions \nrf_predict_data <- as.data.frame(rf_final_result$.predictions) %>%\n  bind_cols(tracks_test)\n\nrf_final_result$.metrics\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.68  Preprocessor1_Model1\n2 roc_auc  binary         0.769 Preprocessor1_Model1\n```\n:::\n\n```{.r .cell-code}\n# roc auc curve\ntest_roc_auc_rf <- roc_curve(test_predict2_rf, name, .pred_anna)\n```\n:::\n\n\n# Comparison of model performance\n\nNow that all of the models are built, we can compare their performance. Let's start by pulling out the metrics from the model results and compare the accuracy of the four models. \n\n::: {.cell}\n\n```{.r .cell-code}\n# store the final result metrics\nknn_metrics <- final_knn_result$.metrics[[1]]\ntree_metrics <- final_tree_result$.metrics[[1]]\nbag_metrics <- final_bag_result$.metrics[[1]]\nrf_metrics <- rf_final_result$.metrics[[1]]\n\n# combine metrics into df for table\ncomparison_data <- data.frame(\n  Model = c(\"KNN\", \"Decision Tree\", \"Bagged Tree\", \"Random Forest\"),\n  Accuracy = c(knn_metrics$.estimate[1], tree_metrics$.estimate[1], bag_metrics$.estimate[1], rf_metrics$.estimate[1]),\n  ROC_AUC = c(knn_metrics$.estimate[2], tree_metrics$.estimate[2], bag_metrics$.estimate[2], rf_metrics$.estimate[2])\n)\n\n# make table\ncomparison_data %>%\n  gt() %>%\n  tab_header(\n    title = \"Model Comparison\",\n    subtitle = \"Accuracy and ROC AUC on Testing Data\"\n  ) %>%\n  fmt_number(\n    columns = c(Accuracy, ROC_AUC),\n    decimals = 3\n  )\n```\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"lurgpbmwxc\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#lurgpbmwxc table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#lurgpbmwxc thead, #lurgpbmwxc tbody, #lurgpbmwxc tfoot, #lurgpbmwxc tr, #lurgpbmwxc td, #lurgpbmwxc th {\n  border-style: none;\n}\n\n#lurgpbmwxc p {\n  margin: 0;\n  padding: 0;\n}\n\n#lurgpbmwxc .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#lurgpbmwxc .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#lurgpbmwxc .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#lurgpbmwxc .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#lurgpbmwxc .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#lurgpbmwxc .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#lurgpbmwxc .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#lurgpbmwxc .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#lurgpbmwxc .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#lurgpbmwxc .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#lurgpbmwxc .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#lurgpbmwxc .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#lurgpbmwxc .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#lurgpbmwxc .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#lurgpbmwxc .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#lurgpbmwxc .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#lurgpbmwxc .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#lurgpbmwxc .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#lurgpbmwxc .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#lurgpbmwxc .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#lurgpbmwxc .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#lurgpbmwxc .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#lurgpbmwxc .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#lurgpbmwxc .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#lurgpbmwxc .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#lurgpbmwxc .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#lurgpbmwxc .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#lurgpbmwxc .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#lurgpbmwxc .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#lurgpbmwxc .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#lurgpbmwxc .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#lurgpbmwxc .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#lurgpbmwxc .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#lurgpbmwxc .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#lurgpbmwxc .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#lurgpbmwxc .gt_left {\n  text-align: left;\n}\n\n#lurgpbmwxc .gt_center {\n  text-align: center;\n}\n\n#lurgpbmwxc .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#lurgpbmwxc .gt_font_normal {\n  font-weight: normal;\n}\n\n#lurgpbmwxc .gt_font_bold {\n  font-weight: bold;\n}\n\n#lurgpbmwxc .gt_font_italic {\n  font-style: italic;\n}\n\n#lurgpbmwxc .gt_super {\n  font-size: 65%;\n}\n\n#lurgpbmwxc .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#lurgpbmwxc .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#lurgpbmwxc .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#lurgpbmwxc .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#lurgpbmwxc .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#lurgpbmwxc .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#lurgpbmwxc .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_heading\">\n      <td colspan=\"3\" class=\"gt_heading gt_title gt_font_normal\" style>Model Comparison</td>\n    </tr>\n    <tr class=\"gt_heading\">\n      <td colspan=\"3\" class=\"gt_heading gt_subtitle gt_font_normal gt_bottom_border\" style>Accuracy and ROC AUC on Testing Data</td>\n    </tr>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Model\">Model</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Accuracy\">Accuracy</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"ROC_AUC\">ROC_AUC</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"Model\" class=\"gt_row gt_left\">KNN</td>\n<td headers=\"Accuracy\" class=\"gt_row gt_right\">0.630</td>\n<td headers=\"ROC_AUC\" class=\"gt_row gt_right\">0.661</td></tr>\n    <tr><td headers=\"Model\" class=\"gt_row gt_left\">Decision Tree</td>\n<td headers=\"Accuracy\" class=\"gt_row gt_right\">0.650</td>\n<td headers=\"ROC_AUC\" class=\"gt_row gt_right\">0.626</td></tr>\n    <tr><td headers=\"Model\" class=\"gt_row gt_left\">Bagged Tree</td>\n<td headers=\"Accuracy\" class=\"gt_row gt_right\">0.700</td>\n<td headers=\"ROC_AUC\" class=\"gt_row gt_right\">0.756</td></tr>\n    <tr><td headers=\"Model\" class=\"gt_row gt_left\">Random Forest</td>\n<td headers=\"Accuracy\" class=\"gt_row gt_right\">0.680</td>\n<td headers=\"ROC_AUC\" class=\"gt_row gt_right\">0.769</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n\nAdditionally, we can visualize our model comparison and look at the confusion matrices for each model. \n\n::: {.cell}\n\n```{.r .cell-code}\n# pivot data for plottig\ncomparison_data_long <- comparison_data %>%\n  pivot_longer(cols = c(Accuracy, ROC_AUC), names_to = \"Metric\", values_to = \"Value\")\n\n# plotting\nggplot(comparison_data_long, aes(x = Model, y = Value, fill = Metric)) +\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.8), width = 0.7, color = \"black\") +\n  labs(title = \"Model Comparison\",\n       y = \"Metric Value\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"lightblue\", \"seagreen\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# confusion matrix\ntest_knn_predict %>%\n  conf_mat(truth = name, estimate = .pred_class) %>%\n  autoplot(type = 'heatmap') +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 30, hjust = 1)) +\n  labs(title = \"KNN\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-26-2.png){width=672}\n:::\n\n```{.r .cell-code}\ntest_predict_rf %>% \n  conf_mat(truth = name, estimate = .pred_class) %>% #create confusion matrix\n  autoplot(type = \"heatmap\") + #plot confusion matrix with heatmap\n  theme_bw() + #change theme\n  theme(axis.text.x = element_text(angle = 30, hjust=1)) +\n  #rotate axis labels\n  labs(title = \"Random Forest\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-26-3.png){width=672}\n:::\n\n```{.r .cell-code}\nbag_data %>%\n  conf_mat(truth = name, estimate = .pred_class) %>%\n  autoplot(type = 'heatmap') +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 30, hjust = 1)) +\n  labs(title = \"Bagged Tree\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-26-4.png){width=672}\n:::\n\n```{.r .cell-code}\npredict_tree_data %>%\n  conf_mat(truth = name, estimate = .pred_class) %>%\n  autoplot(type = 'heatmap') +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 30, hjust = 1)) +\n  labs(title = \"Decision Tree\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-26-5.png){width=672}\n:::\n\n```{.r .cell-code}\n# bag_conf + knn_conf + rf_conf + tree_conf\n```\n:::\n\n\n# Thoughts and Conclusions\n\nThis was a fun project and got me more familiar with machine learning packages in R and modeling methods. I want to explore the Spotify data more, since there are so many more functions and attributes I haven't explored. Happy listening!\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}