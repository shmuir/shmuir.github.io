[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "my_env/lib/python3.11/site-packages/idna-3.6.dist-info/LICENSE.html",
    "href": "my_env/lib/python3.11/site-packages/idna-3.6.dist-info/LICENSE.html",
    "title": "Sam Muir",
    "section": "",
    "text": "BSD 3-Clause License\nCopyright (c) 2013-2023, Kim Davies and contributors. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "my_env/lib/python3.11/site-packages/soupsieve-2.5.dist-info/licenses/LICENSE.html",
    "href": "my_env/lib/python3.11/site-packages/soupsieve-2.5.dist-info/licenses/LICENSE.html",
    "title": "Sam Muir",
    "section": "",
    "text": "MIT License\nCopyright (c) 2018 - 2023 Isaac Muse isaacmuse@gmail.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "my_env/lib/python3.11/site-packages/pyzmq-25.1.1.dist-info/AUTHORS.html",
    "href": "my_env/lib/python3.11/site-packages/pyzmq-25.1.1.dist-info/AUTHORS.html",
    "title": "Sam Muir",
    "section": "",
    "text": "This project was started and continues to be led by Brian E. Granger (ellisonbg AT gmail DOT com). Min Ragan-Kelley (benjaminrk AT gmail DOT com) is the primary developer of pyzmq at this time.\nThe following people have contributed to the project:\n\nAlexander Else (alexander DOT else AT team DOT telstra DOT com)\nAlexander Pyhalov (apyhalov AT gmail DOT com)\nAlexandr Emelin (frvzmb AT gmail DOT com)\nAmr Ali (amr AT ledgerx DOT com)\nAndre Caron (andre DOT l DOT caron AT gmail DOT com)\nAndrea Crotti (andrea DOT crotti DOT 0 AT gmail DOT com)\nAndrew Gwozdziewycz (git AT apgwoz DOT com)\nBaptiste Lepilleur (baptiste DOT lepilleur AT gmail DOT com)\nBrandyn A. White (bwhite AT dappervision DOT com)\nBrian E. Granger (ellisonbg AT gmail DOT com)\nBrian Hoffman (hoffman_brian AT bah DOT com)\nCarlos A. Rocha (carlos DOT rocha AT gmail DOT com)\nChris Laws (clawsicus AT gmail DOT com)\nChristian Wyglendowski (christian AT bu DOT mp)\nChristoph Gohlke (cgohlke AT uci DOT edu)\nCurtis (curtis AT tinbrain DOT net)\nCyril Holweck (cyril DOT holweck AT free DOT fr)\nDan Colish (dcolish AT gmail DOT com)\nDaniel Lundin (dln AT eintr DOT org)\nDaniel Truemper (truemped AT googlemail DOT com)\nDouglas Creager (douglas DOT creager AT redjack DOT com)\nEduardo Stalinho (eduardooc DOT 86 AT gmail DOT com)\nEren Güven (erenguven0 AT gmail DOT com)\nErick Tryzelaar (erick DOT tryzelaar AT gmail DOT com)\nErik Tollerud (erik DOT tollerud AT gmail DOT com)\nFELD Boris (lothiraldan AT gmail DOT com)\nFantix King (fantix DOT king AT gmail DOT com)\nFelipe Cruz (felipecruz AT loogica DOT net)\nFernando Perez (Fernando DOT Perez AT berkeley DOT edu)\nFrank Wiles (frank AT revsys DOT com)\nFélix-Antoine Fortin (felix DOT antoine DOT fortin AT gmail DOT com)\nGavrie Philipson (gavriep AT il DOT ibm DOT com)\nGodefroid Chapelle (gotcha AT bubblenet DOT be)\nGreg Banks (gbanks AT mybasis DOT com)\nGreg Ward (greg AT gerg DOT ca)\nGuido Goldstein (github AT a-nugget DOT de)\nIan Lee (IanLee1521 AT gmail DOT com)\nIonuț Arțăriși (ionut AT artarisi DOT eu)\nIvo Danihelka (ivo AT danihelka DOT net)\nIyed (iyed DOT bennour AT gmail DOT com)\nJim Garrison (jim AT garrison DOT cc)\nJohn Gallagher (johnkgallagher AT gmail DOT com)\nJulian Taylor (jtaylor DOT debian AT googlemail DOT com)\nJustin Bronder (jsbronder AT gmail DOT com)\nJustin Riley (justin DOT t DOT riley AT gmail DOT com)\nMarc Abramowitz (marc AT marc-abramowitz DOT com)\nMatthew Aburn (mattja6 AT gmail DOT com)\nMichel Pelletier (pelletier DOT michel AT gmail DOT com)\nMichel Zou (xantares09 AT hotmail DOT com)\nMin Ragan-Kelley (benjaminrk AT gmail DOT com)\nNell Hardcastle (nell AT dev-nell DOT com)\nNicholas Pilkington (nicholas DOT pilkington AT gmail DOT com)\nNicholas Piël (nicholas AT nichol DOT as)\nNick Pellegrino (npellegrino AT mozilla DOT com)\nNicolas Delaby (nicolas DOT delaby AT ezeep DOT com)\nOndrej Certik (ondrej AT certik DOT cz)\nPaul Colomiets (paul AT colomiets DOT name)\nPawel Jasinski (pawel DOT jasinski AT gmail DOT com)\nPhus Lu (phus DOT lu AT gmail DOT com)\nRobert Buchholz (rbu AT goodpoint DOT de)\nRobert Jordens (jordens AT gmail DOT com)\nRyan Cox (ryan DOT a DOT cox AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nScott Maxwell (scott AT codecobblers DOT com)\nScott Sadler (github AT mashi DOT org)\nSimon Knight (simon DOT knight AT gmail DOT com)\nStefan Friesel (sf AT cloudcontrol DOT de)\nStefan van der Walt (stefan AT sun DOT ac DOT za)\nStephen Diehl (stephen DOT m DOT diehl AT gmail DOT com)\nSylvain Corlay (scorlay AT bloomberg DOT net)\nThomas Kluyver (takowl AT gmail DOT com)\nThomas Spura (tomspur AT fedoraproject DOT org)\nTigger Bear (Tigger AT Tiggers-Mac-mini DOT local)\nTorsten Landschoff (torsten DOT landschoff AT dynamore DOT de)\nVadim Markovtsev (v DOT markovtsev AT samsung DOT com)\nYannick Hold (yannickhold AT gmail DOT com)\nZbigniew Jędrzejewski-Szmek (zbyszek AT in DOT waw DOT pl)\nhugo shi (hugoshi AT bleb2 DOT (none))\njdgleeson (jdgleeson AT mac DOT com)\nkyledj (kyle AT bucebuce DOT com)\nspez (steve AT hipmunk DOT com)\nstu (stuart DOT axon AT jpcreative DOT co DOT uk)\nxantares (xantares AT fujitsu-l64 DOT (none))\n\nas reported by:\ngit log --all --format='- %aN (%aE)' | sort -u | sed 's/@/ AT /1' | sed -e 's/\\.\\([^ ]\\)/ DOT \\1/g'\nwith some adjustments.\n\n\n\nBrandon Craig-Rhodes (brandon AT rhodesmill DOT org)\nEugene Chernyshov (chernyshov DOT eugene AT gmail DOT com)\nCraig Austin (craig DOT austin AT gmail DOT com)\n\n\n\n\n\nTravis Cline (travis DOT cline AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nZachary Voase (z AT zacharyvoase DOT com)"
  },
  {
    "objectID": "my_env/lib/python3.11/site-packages/pyzmq-25.1.1.dist-info/AUTHORS.html#authors",
    "href": "my_env/lib/python3.11/site-packages/pyzmq-25.1.1.dist-info/AUTHORS.html#authors",
    "title": "Sam Muir",
    "section": "",
    "text": "This project was started and continues to be led by Brian E. Granger (ellisonbg AT gmail DOT com). Min Ragan-Kelley (benjaminrk AT gmail DOT com) is the primary developer of pyzmq at this time.\nThe following people have contributed to the project:\n\nAlexander Else (alexander DOT else AT team DOT telstra DOT com)\nAlexander Pyhalov (apyhalov AT gmail DOT com)\nAlexandr Emelin (frvzmb AT gmail DOT com)\nAmr Ali (amr AT ledgerx DOT com)\nAndre Caron (andre DOT l DOT caron AT gmail DOT com)\nAndrea Crotti (andrea DOT crotti DOT 0 AT gmail DOT com)\nAndrew Gwozdziewycz (git AT apgwoz DOT com)\nBaptiste Lepilleur (baptiste DOT lepilleur AT gmail DOT com)\nBrandyn A. White (bwhite AT dappervision DOT com)\nBrian E. Granger (ellisonbg AT gmail DOT com)\nBrian Hoffman (hoffman_brian AT bah DOT com)\nCarlos A. Rocha (carlos DOT rocha AT gmail DOT com)\nChris Laws (clawsicus AT gmail DOT com)\nChristian Wyglendowski (christian AT bu DOT mp)\nChristoph Gohlke (cgohlke AT uci DOT edu)\nCurtis (curtis AT tinbrain DOT net)\nCyril Holweck (cyril DOT holweck AT free DOT fr)\nDan Colish (dcolish AT gmail DOT com)\nDaniel Lundin (dln AT eintr DOT org)\nDaniel Truemper (truemped AT googlemail DOT com)\nDouglas Creager (douglas DOT creager AT redjack DOT com)\nEduardo Stalinho (eduardooc DOT 86 AT gmail DOT com)\nEren Güven (erenguven0 AT gmail DOT com)\nErick Tryzelaar (erick DOT tryzelaar AT gmail DOT com)\nErik Tollerud (erik DOT tollerud AT gmail DOT com)\nFELD Boris (lothiraldan AT gmail DOT com)\nFantix King (fantix DOT king AT gmail DOT com)\nFelipe Cruz (felipecruz AT loogica DOT net)\nFernando Perez (Fernando DOT Perez AT berkeley DOT edu)\nFrank Wiles (frank AT revsys DOT com)\nFélix-Antoine Fortin (felix DOT antoine DOT fortin AT gmail DOT com)\nGavrie Philipson (gavriep AT il DOT ibm DOT com)\nGodefroid Chapelle (gotcha AT bubblenet DOT be)\nGreg Banks (gbanks AT mybasis DOT com)\nGreg Ward (greg AT gerg DOT ca)\nGuido Goldstein (github AT a-nugget DOT de)\nIan Lee (IanLee1521 AT gmail DOT com)\nIonuț Arțăriși (ionut AT artarisi DOT eu)\nIvo Danihelka (ivo AT danihelka DOT net)\nIyed (iyed DOT bennour AT gmail DOT com)\nJim Garrison (jim AT garrison DOT cc)\nJohn Gallagher (johnkgallagher AT gmail DOT com)\nJulian Taylor (jtaylor DOT debian AT googlemail DOT com)\nJustin Bronder (jsbronder AT gmail DOT com)\nJustin Riley (justin DOT t DOT riley AT gmail DOT com)\nMarc Abramowitz (marc AT marc-abramowitz DOT com)\nMatthew Aburn (mattja6 AT gmail DOT com)\nMichel Pelletier (pelletier DOT michel AT gmail DOT com)\nMichel Zou (xantares09 AT hotmail DOT com)\nMin Ragan-Kelley (benjaminrk AT gmail DOT com)\nNell Hardcastle (nell AT dev-nell DOT com)\nNicholas Pilkington (nicholas DOT pilkington AT gmail DOT com)\nNicholas Piël (nicholas AT nichol DOT as)\nNick Pellegrino (npellegrino AT mozilla DOT com)\nNicolas Delaby (nicolas DOT delaby AT ezeep DOT com)\nOndrej Certik (ondrej AT certik DOT cz)\nPaul Colomiets (paul AT colomiets DOT name)\nPawel Jasinski (pawel DOT jasinski AT gmail DOT com)\nPhus Lu (phus DOT lu AT gmail DOT com)\nRobert Buchholz (rbu AT goodpoint DOT de)\nRobert Jordens (jordens AT gmail DOT com)\nRyan Cox (ryan DOT a DOT cox AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nScott Maxwell (scott AT codecobblers DOT com)\nScott Sadler (github AT mashi DOT org)\nSimon Knight (simon DOT knight AT gmail DOT com)\nStefan Friesel (sf AT cloudcontrol DOT de)\nStefan van der Walt (stefan AT sun DOT ac DOT za)\nStephen Diehl (stephen DOT m DOT diehl AT gmail DOT com)\nSylvain Corlay (scorlay AT bloomberg DOT net)\nThomas Kluyver (takowl AT gmail DOT com)\nThomas Spura (tomspur AT fedoraproject DOT org)\nTigger Bear (Tigger AT Tiggers-Mac-mini DOT local)\nTorsten Landschoff (torsten DOT landschoff AT dynamore DOT de)\nVadim Markovtsev (v DOT markovtsev AT samsung DOT com)\nYannick Hold (yannickhold AT gmail DOT com)\nZbigniew Jędrzejewski-Szmek (zbyszek AT in DOT waw DOT pl)\nhugo shi (hugoshi AT bleb2 DOT (none))\njdgleeson (jdgleeson AT mac DOT com)\nkyledj (kyle AT bucebuce DOT com)\nspez (steve AT hipmunk DOT com)\nstu (stuart DOT axon AT jpcreative DOT co DOT uk)\nxantares (xantares AT fujitsu-l64 DOT (none))\n\nas reported by:\ngit log --all --format='- %aN (%aE)' | sort -u | sed 's/@/ AT /1' | sed -e 's/\\.\\([^ ]\\)/ DOT \\1/g'\nwith some adjustments.\n\n\n\nBrandon Craig-Rhodes (brandon AT rhodesmill DOT org)\nEugene Chernyshov (chernyshov DOT eugene AT gmail DOT com)\nCraig Austin (craig DOT austin AT gmail DOT com)\n\n\n\n\n\nTravis Cline (travis DOT cline AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nZachary Voase (z AT zacharyvoase DOT com)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "A bit about me professionally and personally",
    "section": "",
    "text": "I am currently an intern with the USDA USFS with support from the Conference on Asian Pacific American Leadership. In this role I am working to further environmental equity in K-12 public schools in California through tree cover mapping and remote sensing. Additionally, I am continuing my role as an Arnhold Environmental Graduate Fellow, working with the emLab and Conservation International, focusing on elephant habitat connectivity under climate change and land cover shifts.\n\n\n\n\n\n\n\n\nWatering research Acmispon plants in the SMCM greenhouse!"
  },
  {
    "objectID": "about.html#fa-code-currently",
    "href": "about.html#fa-code-currently",
    "title": "A bit about me professionally and personally",
    "section": "",
    "text": "I am currently an intern with the USDA USFS with support from the Conference on Asian Pacific American Leadership. In this role I am working to further environmental equity in K-12 public schools in California through tree cover mapping and remote sensing. Additionally, I am continuing my role as an Arnhold Environmental Graduate Fellow, working with the emLab and Conservation International, focusing on elephant habitat connectivity under climate change and land cover shifts.\n\n\n\n\n\n\n\n\nWatering research Acmispon plants in the SMCM greenhouse!"
  },
  {
    "objectID": "about.html#fa-bacteria-previously",
    "href": "about.html#fa-bacteria-previously",
    "title": "A bit about me professionally and personally",
    "section": " Previously",
    "text": "Previously\nIn June 2024, I graduated from the Masters of Environmental Data Science program at the Bren School at the University of California, Santa Barbara. My masters project focused on identifying high-priority survey sites for milkweed conservation in the Los Padres National Forest for the Santa Barbara Botanic Garden.\nPreviously, I completed my undergraduate degrees in Biology and Environmental Studies (+ French Minor) at St. Mary’s College of Maryland (SMCM) where I had two main areas of focus: plant sciences and coastal ecology. I conducted research on salinity effects on plant-microbe interactions in a plant ecology lab where I was also the lab manager. My undergraduate thesis examined coastal wave mitigation by constructed oyster reefs using DIY wave gauges. I continued on with submerged aquatic vegetation research with my same thesis advisor. Towards the end of my undergraduate experience, I also discovered my passion for environmental data science and GIS.\n\n\n\n\n\n\n\n\nCollege sailing nationals 2022 at Tulane University."
  },
  {
    "objectID": "about.html#fa-sailboat-personally",
    "href": "about.html#fa-sailboat-personally",
    "title": "A bit about me professionally and personally",
    "section": " Personally",
    "text": "Personally\nA big part of my life has been devoted to dinghy sailing, especially during undergrad. I was on the SMCM varsity sailing team and was a captain for two years. During this time, I competed all over the country, ending my sailing career with multiple conference championship victories, a team top-ten national ranking, two All-America titles, and wonderful memories with amazing teammates who became another family.\n\n\n\n\n\n\n\n\nSometimes music is best enjoyed (and played) outside :)\n\nNow that I’m not sailing as much, I have been able to devote more time to other hobbies including running, playing cello, and transcribing/ arranging music. During 2020, I began arranging music for me and my dad (a flautist) to play together. I mainly use the MuseScore4 engraving software and am working on uploading my transcriptions and arrangements to my MuseScore profile - check it out!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sam Muir",
    "section": "",
    "text": "My name is Sam and I am recent graduate from the Master of Environmental Data Science program at the Bren School of Environmental Science & Management at the University of California, Santa Barbara. My experience encompasses a range of projects focused on land cover change, spatial modeling, and the impacts of climate change on environmental health. I’m eager to continue developing my environmental data science skills, leverage my experience to help protect our vital ecosystems, and contribute to environmental justice efforts through accessible science communication."
  },
  {
    "objectID": "index.html#hello",
    "href": "index.html#hello",
    "title": "Sam Muir",
    "section": "",
    "text": "My name is Sam and I am recent graduate from the Master of Environmental Data Science program at the Bren School of Environmental Science & Management at the University of California, Santa Barbara. My experience encompasses a range of projects focused on land cover change, spatial modeling, and the impacts of climate change on environmental health. I’m eager to continue developing my environmental data science skills, leverage my experience to help protect our vital ecosystems, and contribute to environmental justice efforts through accessible science communication."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Sam Muir",
    "section": "Education",
    "text": "Education\nMaster of Environmental Data Science (MEDS)  University of California Santa Barbara (2024)\nB.S. Biology and B.A. Environmental Studies, Minor in French  St. Mary’s College of Maryland (2023)"
  },
  {
    "objectID": "projects/2023-11-26-houston-power-outage/index.html",
    "href": "projects/2023-11-26-houston-power-outage/index.html",
    "title": "Identifying power outages in Houston, TX from February 2021 storms",
    "section": "",
    "text": "In February 2021, the state of Texas suffered a major energy crisis as a result of three severe winter storms and left many people without power. Historically, power outages may disproportionately affect marginalized groups and lower-income areas can be of lower priority in recovery. For more background: engineering and political perspectives.\nIn this post, I am interested in estimating the number of homes in Houston that lost power as a result of the first two storm and investigating if there is a correlation between loss of power and socioeconomic status."
  },
  {
    "objectID": "projects/2023-11-26-houston-power-outage/index.html#night-lights",
    "href": "projects/2023-11-26-houston-power-outage/index.html#night-lights",
    "title": "Identifying power outages in Houston, TX from February 2021 storms",
    "section": "Night Lights",
    "text": "Night Lights\nSince these night light files are quite large, I am using stars::read_stars() to work with the raster data. Here I have two tiles for 2021-02-07 and two tiles for 2021-02-16.\n\n\nCode\n# read in night light files using read_stars()\nfeb7_1 &lt;- read_stars(\"data/VNP46A1/VNP46A1.A2021038.h08v05.001.2021039064328.tif\")\nfeb7_2 &lt;- read_stars(\"data/VNP46A1/VNP46A1.A2021038.h08v06.001.2021039064329.tif\")\nfeb16_1 &lt;- read_stars(\"data/VNP46A1/VNP46A1.A2021047.h08v05.001.2021048091106.tif\")\nfeb16_2 &lt;- read_stars(\"data/VNP46A1/VNP46A1.A2021047.h08v06.001.2021048091105.tif\")\n\n\nThe tile pairs now need to be combined to create a full image of out area of interest.\n\n\nCode\n# combine both feb. 7th\nfeb7 &lt;- st_mosaic(feb7_1, feb7_2)\n\n# combine both feb. 16th\nfeb16 &lt;- st_mosaic(feb16_1, feb16_2)\n\n\nNow that we have the full area we can begin finding the difference light intensity.\nTo find if there is a different in the night lights from before and after the storm, I found the different between the light intensity, assuming that any location that experienced a drop of more than 200 nW cm-2sr-1 experienced a power outage.\n\n\nCode\n# finding the difference in night lights\nnight_diff &lt;- (feb7 - feb16)\n#plot(night_diff, main = \"Difference in night light\")\n\n# create a mask, sectioning in to 200 to infinity; the rest become NA\nnight_mask &lt;- cut(night_diff, c(200, Inf), labels = \"outage\")\n\n# the night mask should have one level \"outage\" and NA for the rest; check using:\n# unique(night_mask$VNP46A1.A2021038.h08v05.001.2021039064328.tif)\n\n# vectorizing night_mask using st_as_sf\nnight_mask_vec &lt;- st_as_sf(night_mask) %&gt;%\n  st_make_valid() # fix invalid geometries\n\n# checking that it is now sf data.frame\n# class(night_mask_vec)\n\n\nIn this project I am wanting to specifically look at Houston, and right now, the map covers more area than just Houston. To focus in on Houston, I first need to define the coordinates of the city boundary and then turn them into a polygon and simple features collection.\n\n\nCode\n# creating Houston border with the given coordinates using st_polygon()\nhouston_border &lt;- st_polygon(list(rbind(c(-96.5,29), c(-96.5,30.5), c(-94.5, 30.5), c(-94.5,29), c(-96.5,29)))) # rbind combines objects\n\n# convert to sfc and define crs\nhouston_border_sf &lt;- st_sfc(houston_border, crs = 'EPSG:4326')\n\n\nNow that the boarder is defined, I can use it to crop the blackout mask. Additionally, I need to make sure that both of the objects have the same coordinate reference system (CRS), and in this case, I want to use EPSG:3083 (NAD83 / Texas Centric Albers Equal Area).\n\n\nCode\n# crop using the Houston border\nhouston_mask &lt;- night_mask_vec[houston_border_sf, ,] # subset using the border object\n\n# reproject cropped object to new crs\noutage_mask &lt;- st_transform(houston_mask, crs = 'EPSG:3083')\n#plot(outage_mask)"
  },
  {
    "objectID": "projects/2023-11-26-houston-power-outage/index.html#highways",
    "href": "projects/2023-11-26-houston-power-outage/index.html#highways",
    "title": "Identifying power outages in Houston, TX from February 2021 storms",
    "section": "Highways",
    "text": "Highways\nHighways often make up a large portion of observable night light and this is not something I want to capture. So, using the roads data, I will exclude areas with roads, as well as include a 200m buffer around the roads.\nThis data includes more than just highways, so it is important to select just the highways (motorways).\n\n\nCode\n## highway data ##\n# define sql query\nquery_highways &lt;- \"SELECT * FROM gis_osm_roads_free_1 WHERE fclass='motorway'\"\n\n# load highway data using the query and reproject to EPSG:3083\nhighways &lt;- st_read(\"data/gis_osm_roads_free_1.gpkg\", query = query_highways) %&gt;%\n  st_transform(highways, crs = 'EPSG:3083')\n\n# highway buffer setting distance to 200m\nhighway_buffer &lt;- st_buffer(x = highways, dist = 200) %&gt;%\n  st_union() # dissolve undissolved buffers\n\n\nUsing the newly prepared highway data, I can now exclude areas within 200m of a highway.\n\n\nCode\n# combine the geometries and exclude those within 200m of a highway\nmask_houston_highway &lt;- st_difference(outage_mask, highway_buffer)\n\n## check that areas have been excluded ##\n# nrow(mask_houston_highway) &gt; nrow(outage_mask) # output should be FALSE \n# plot(mask_houston_highway) # check out what it looks like\n\n\nThere were 7247 areas that experienced blackouts that are further than 200m from a highway."
  },
  {
    "objectID": "projects/2023-11-26-houston-power-outage/index.html#homes",
    "href": "projects/2023-11-26-houston-power-outage/index.html#homes",
    "title": "Identifying power outages in Houston, TX from February 2021 storms",
    "section": "Homes",
    "text": "Homes\nNow that we have accounted for the highways it’s time to find the number of homes that experienced a blackout. Similarly to the road data, the data set that contains information on homes also contains other building types, so it’s important to select only residential buildings (and to make sure the CRS is EPSG:3083!).\n\n\nCode\n## houses data ##\n# define sql query\nquery_houses &lt;- \"SELECT * FROM gis_osm_buildings_a_free_1 WHERE (type IS NULL AND name IS NULL) OR type in ('residential', 'apartments', 'house', 'static_caravan', 'detached')\"\n\n# read in the houses data using query\nhouses &lt;- st_read(\"data/gis_osm_buildings_a_free_1.gpkg\", query = query_houses)\n\n# transform crs\nhouses &lt;- st_transform(houses, crs = 'EPSG:3083')\n#plot(houses['type'])\n\n# filter houses data using the blackout mask\noutage_houses &lt;- houses[mask_houston_highway, drop = FALSE]\n\n# check and see that filtered data has fewer houses than the original\n# nrow(houses) &gt; nrow(outage_houses)\n\n\nThere were 157411 homes in Houston affected by the power outage."
  },
  {
    "objectID": "projects/2023-11-26-houston-power-outage/index.html#median-income",
    "href": "projects/2023-11-26-houston-power-outage/index.html#median-income",
    "title": "Identifying power outages in Houston, TX from February 2021 storms",
    "section": "Median Income",
    "text": "Median Income\nThe last data that needs to be prepared is the income data. From the geodatabase, we want the census tract geometries and the median income.\n\n\nCode\n# Texas geometries data and transform crs\ncensus_geom &lt;- st_read(\"data/ACS_2019_5YR_TRACT_48_TEXAS.gdb\", layer = \"ACS_2019_5YR_TRACT_48_TEXAS\") %&gt;%\n  st_transform(census_geom, crs = 'EPSG:3083')\n#st_crs(census_geom) # check the crs is correct\n\n# income data\nincome &lt;- st_read(\"data/ACS_2019_5YR_TRACT_48_TEXAS.gdb\", layer = \"X19_INCOME\")\n\n# select variables; rename median income and GEOID to match census_geom\nincome_median &lt;- income %&gt;% \n  select(GEOID, B19013e1) %&gt;% \n  rename(median_income = B19013e1, GEOID_Data = GEOID)"
  },
  {
    "objectID": "projects/2024-04-13-spotify-predictions/index.html",
    "href": "projects/2024-04-13-spotify-predictions/index.html",
    "title": "Who’s on AUX? Using machine learning to predict whose Spotify playlist a song belongs to",
    "section": "",
    "text": "In this project, I am interested in building my machine learning skills through a fun exercise with Spotify!\nUsing my liked songs and my friends, can I build a machine learning model to predict whose playlist a song belongs to?"
  },
  {
    "objectID": "projects/2024-04-13-spotify-predictions/index.html#data-preparation",
    "href": "projects/2024-04-13-spotify-predictions/index.html#data-preparation",
    "title": "Who’s on AUX? Using machine learning to predict whose Spotify playlist a song belongs to",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nSys.setenv(SPOTIFY_CLIENT_ID = SPOTIFY_CLIENT_ID)\nSys.setenv(SPOTIFY_CLIENT_SECRET = SPOTIFY_CLIENT_SECRET)\n\nauthorization_code &lt;- get_spotify_authorization_code(scope = scopes()[c(1:19)]) #sets an authorization code that you'll need to provide for certain get_ functions via my_tracks &lt;- get_my_saved_tracks(authorization = authorization_code)\n\naccess_token &lt;- get_spotify_access_token() #takes ID and SECRET, sends to Spotify and receives an access token\n\nUsing get_my_saved_tracks(), the Spotify API returns a dataframe of tracks and associated attributes. However, it will only return up to 50 tracks at a time, so I will need to make multiple requests. To do this, I will use a function to combine all the requests in one call.\n\noffsets = seq(from = 0, to = 150, by = 50)\n\n#initializing an empty df\nmy_tracks &lt;- data.frame(matrix(nrow = 0, ncol = 30))\n\n# function to get my 150 most recently liked tracks\nfor (i in seq_along(offsets)) {\n  liked_tracks = get_my_saved_tracks(authorization = authorization_code, limit = 50,\n                                     offset = offsets[i])\n  df_temp = as.data.frame(liked_tracks) # creating a temporary data frame\n  my_tracks &lt;- rbind(my_tracks, df_temp) # binding the temporary data frame to my tracks data frame\n}\n\nAdditionally, by giving the API a list of track IDs using get_track_audio_features(), I can get an audio features dataframe of all the tracks and some attributes of them.\n\naudio1 &lt;- get_track_audio_features(my_tracks$track.id[1:100])\naudio2 &lt;- get_track_audio_features(my_tracks$track.id[101:200])\n\naudio_features &lt;- rbind(audio1, audio2)\n\nThese track audio features are the predictors we are interested in, but this dataframe doesn’t have the actual names of the tracks, so I need to append the ‘track.name’ column from my favorite tracks dataframe.\n\nsam_audio &lt;- my_tracks %&gt;%\n  select(track.name) %&gt;%\n  bind_cols(audio_features) %&gt;%\n  mutate(name = \"sam\")\n\nOne of my friends followed these same steps, and she sent me a .csv of her track audio features, which I will bind with my audio features dataframe.\n\n# read in anna audio\nanna_audio &lt;- read_csv(here::here(\"projects/2024-04-13-spotify-predictions/named_audio_anna.csv\")) %&gt;%\n  mutate(name = \"anna\")\n\n# bind mine and anna's data \nboth_audio &lt;- rbind(sam_audio, anna_audio)"
  },
  {
    "objectID": "projects/2024-04-13-spotify-predictions/index.html#data-exploration",
    "href": "projects/2024-04-13-spotify-predictions/index.html#data-exploration",
    "title": "Who’s on AUX? Using machine learning to predict whose Spotify playlist a song belongs to",
    "section": "Data Exploration",
    "text": "Data Exploration\nNow that the data is ready to go, let’s do a little data exploration. There are a lot of cool audio features to explore.\n\nggplot(both_audio, aes(x = danceability, fill = name)) +\n  geom_density(alpha=0.5) +\n  scale_fill_manual(values=c(\"magenta4\", \"seagreen\"))+\n  labs(x=\"Danceability\", y=\"Density\", title = \"Distribution of Music Danceability Data\") +\n  guides(fill=guide_legend(title=\"Listener\")) +\n  theme_minimal()\n\n\n\nggplot(both_audio, aes(x = energy, fill = name)) +\n  geom_density(alpha=0.6) +\n  scale_fill_manual(values=c(\"magenta4\", \"seagreen\"))+\n  labs(x=\"Energy\", y=\"Density\", title = \"Distribution of Music Energy Data\") +\n  guides(fill=guide_legend(title=\"Listener\")) +\n  theme_minimal()\n\n\n\nrbind(anna_audio[which.max(anna_audio$danceability),],\n      sam_audio[which.max(sam_audio$danceability),]) %&gt;%\n  select(track.name, danceability, name) %&gt;%\n  gt::gt(caption = \"Liked tracks with the highest danceability\")\n\n\n\n\n\n  Liked tracks with the highest danceability\n  \n    \n    \n      track.name\n      danceability\n      name\n    \n  \n  \n    Chilling At Nemu's Place\n0.943\nanna\n    Als ich ein Kind war\n0.948\nsam"
  },
  {
    "objectID": "projects/2024-04-13-spotify-predictions/index.html#modeling-prep",
    "href": "projects/2024-04-13-spotify-predictions/index.html#modeling-prep",
    "title": "Who’s on AUX? Using machine learning to predict whose Spotify playlist a song belongs to",
    "section": "Modeling Prep",
    "text": "Modeling Prep\nFurther preparation is needed before running the models. First, I need to remove unnecessary columns including track urls and the track name. Next I’ll split the data into training and testing sets, using a 75:25 split. Finally, I’ll create my recipe, normalizing the nominal and numeric predictors and prep.\n\n# prepare data ----\nall_tracks_modeling &lt;- both_audio %&gt;%  \n  mutate_if(is.ordered, .funs = factor, ordered = F) %&gt;%\n  select(-track.name, -type, -id, -uri, -track_href, -analysis_url) %&gt;%\n  mutate(name = as.factor(name))\n\n# splitting the data ----\nset.seed(123)\n\ntracks_split &lt;- initial_split(all_tracks_modeling, prop = 0.75)\ntracks_train &lt;- training(tracks_split)\ntracks_test &lt;- testing(tracks_split)\n\n# create a recipe ----\ntracks_recipe &lt;- recipe(name ~ ., data = tracks_train) %&gt;%\n  step_dummy(all_nominal_predictors()) %&gt;%\n  step_normalize(all_numeric_predictors()) %&gt;% #normalize numeric to make sure scale is okay\n  prep()"
  },
  {
    "objectID": "projects/2024-04-13-spotify-predictions/index.html#k-nearest-neighbor",
    "href": "projects/2024-04-13-spotify-predictions/index.html#k-nearest-neighbor",
    "title": "Who’s on AUX? Using machine learning to predict whose Spotify playlist a song belongs to",
    "section": "K-Nearest Neighbor",
    "text": "K-Nearest Neighbor\nThe first model I want to build uses k-nearest neighbor. This is a classification problem (classifying the track as either belonging to my liked songs or my friends liked songs), so I will set_mode() to “classification” and set_engine() to “kknn”.\n\n# Define our KNN model with tuning ----\nknn_spec_tune &lt;- nearest_neighbor(neighbor = tune()) %&gt;%\n  set_mode(\"classification\") %&gt;%\n  set_engine(\"kknn\")\n\n# Check the model\n#knn_spec_tune\n\nNext I need to define my workflow by adding the model and recipe I defined above.\n\n# Define a new workflow ----\nwf_knn_tune &lt;- workflow() %&gt;%\n  add_model(knn_spec_tune) %&gt;%\n  add_recipe(tracks_recipe)\n\nTo hopefully increase the accuracy of my model, I will use 10 fold cross validation to further split and train on my data.\n\n# 10-fold CV on the training dataset ----\nset.seed(123)\n\ncv_folds &lt;- tracks_train %&gt;%\n  vfold_cv(v = 10)\n\nNow that everything is ready to go, I can fit the workflow on the folds and check out the parameter tuning.\n\n# Fit the workflow on our predefined folds and hyperparameters ----\nfit_knn_cv &lt;- wf_knn_tune %&gt;%\n  tune_grid(resamples = cv_folds,\n            grid = 10)\n    \n# Check the performance with collect_metrics()\n#collect_metrics(fit_knn_cv)\n\n# plot cv results for parameter tuning ----\nautoplot(fit_knn_cv) + \n  theme_bw()\n\n\n\n\nUsing the fit workflow, I can finalize and select the best iteration based on the ROC AUC and predict on the training and testing data.\n\n# The final workflow for our KNN model ----\nfinal_knn_wf &lt;- wf_knn_tune %&gt;%\n  finalize_workflow(select_best(fit_knn_cv, metric = \"roc_auc\"))\n\ntrain_knn_fit &lt;- fit(final_knn_wf, tracks_train)\n\ntrain_predict &lt;- predict(object = train_knn_fit, new_data = tracks_train) %&gt;% #predict the training set\n  bind_cols(tracks_train) #bind training set column to prediction\n\ntest_knn_predict &lt;- predict(train_knn_fit, tracks_test) %&gt;% #get prediction probabilities for test \n  bind_cols(tracks_test) %&gt;%  #bind to testing column\n  mutate(name = as.factor(name))\n\nWith my model now finalized, we can look at the accuracy of the training predictions compared to the testing predictions.\n\n# report the accuracy for the training and testing ----\naccuracy(train_predict, truth = name, estimate = .pred_class) #get training accuracy\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.823\n\naccuracy(test_knn_predict, truth = name, estimate = .pred_class) #get accuracy of testing prediction\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary          0.63\n\n\nHere is the optimized workflow for the KNN model along with the result metrics.\n\n# Optimizing workflow ----\nfinal_knn_fit &lt;- final_knn_wf %&gt;% \n  last_fit(tracks_split)\n\n# last_fit() fit on the training data but then also evaluates on the testing data\nfinal_knn_result &lt;- last_fit(final_knn_wf, tracks_split)\n\n# testing predictions and metrics ----\n#final_knn_result$.predictions \nknn_predict_data &lt;- as.data.frame(final_knn_result$.predictions) %&gt;%\n  bind_cols(tracks_test)\n\nfinal_knn_result$.metrics\n\n[[1]]\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.63  Preprocessor1_Model1\n2 roc_auc  binary         0.661 Preprocessor1_Model1\n\n\n\nDecision Tree\nLet’s build another model! This time I am going to be building a decision tree and tuning model hyperparameters. The hyperparameters I have chosen to tune are cost complexity, tree depth, and the minimum number of data points in a node.\n\n#new spec, tell the model that we are tuning hyperparams ----\ntree_spec_tune &lt;- decision_tree(\n  cost_complexity = tune(),\n  tree_depth = tune(),\n  min_n = tune()\n) %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\ntree_grid &lt;- grid_regular(cost_complexity(), tree_depth(), min_n(), levels = 5)\n#head(tree_grid)\n\nNow I can define a new workflow and set up the k-folds\n\n# setting up the workflow ----\nwf_tree_tune &lt;- workflow() %&gt;%\n  add_recipe(tracks_recipe) %&gt;%\n  add_model(tree_spec_tune)\n\n# set up k-fold cv ----\ntracks_cv &lt;- tracks_train %&gt;%\n  vfold_cv(v=10)\n#tracks_cv\n\nSince the decision tree is more computationally expensive, I am going to be using parallel processing to help with grid tuning computation time.\n\n# build trees ----\ndoParallel::registerDoParallel() #build trees in parallel\ntree_rs &lt;- tune_grid(\n  wf_tree_tune,\n  resamples = tracks_cv,\n  grid = tree_grid,\n  metrics = metric_set(accuracy)\n)\n\n# Use autoplot() to examine how different parameter configurations relate to accuracy ----\nautoplot(tree_rs) +\n  theme_bw()\n\n\n\n\nWith the grid tuning finished I can select the best hyperparameters, finalize the workflow, fit the data, and make predictions on the testing data.\n\n# select hyperparameter ----\n#show_best(tree_rs) # showing\nselect_best(tree_rs) # what we'll input\n\n# A tibble: 1 × 4\n  cost_complexity tree_depth min_n .config               \n            &lt;dbl&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;                 \n1    0.0000000001          4    30 Preprocessor1_Model081\n\n# finalize the model specification where we have replaced the tune functions with optimized values ----\nfinal_tree &lt;- finalize_workflow(wf_tree_tune, select_best(tree_rs))\n#final_tree\n\n# final fitting ----\nfinal_tree_fit &lt;- fit(final_tree, data = tracks_train) \n\n# last_fit() fit on the training data but then also evaluates on the testing data\nfinal_tree_result &lt;- last_fit(final_tree, tracks_split)\n\n# testing predictions and metrics ----\n#final_tree_result$.predictions \nfinal_tree_result$.metrics\n\n[[1]]\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.65  Preprocessor1_Model1\n2 roc_auc  binary         0.626 Preprocessor1_Model1\n\npredict_tree_data &lt;- predict(final_tree_fit, tracks_test) %&gt;% #get prediction probabilities for test \n  bind_cols(tracks_test) %&gt;%  #bind to testing column\n  mutate(name = as.factor(name))\n\n#Visualize variable importance ----\nfinal_tree_fit %&gt;%\n  vip(geom = \"point\") +\n  theme_bw()"
  },
  {
    "objectID": "projects/2024-04-13-spotify-predictions/index.html#bagged-tree",
    "href": "projects/2024-04-13-spotify-predictions/index.html#bagged-tree",
    "title": "Who’s on AUX? Using machine learning to predict whose Spotify playlist a song belongs to",
    "section": "Bagged Tree",
    "text": "Bagged Tree\nThe third model I am going to build is a bagged tree model where I tune the cost complexity and the minimum number of data points in a node.\n\n# set up the bagged tree model ----\nbagged_tree &lt;- bag_tree(\n  cost_complexity = tune(),\n  min_n = tune()\n) %&gt;%\n  set_engine(\"rpart\", times = 50) %&gt;%\n  set_mode(\"classification\")\n\nSetting up the workflow and grid tuning.\n\n# workflow ----\nwf_bag_tune &lt;- workflow() %&gt;%\n  add_recipe(tracks_recipe) %&gt;%\n  add_model(bagged_tree)\n\n# set up the tuning ----\nbag_grid &lt;- grid_regular(cost_complexity(), min_n(), levels = 5)\n\nbag_rs &lt;- tune_grid(\n  wf_bag_tune,\n  resamples = tracks_cv,\n  grid = bag_grid,\n  metrics = metric_set(accuracy))\n\nSelect the best hyperparameters, finalize the workflow, fit, and predict.\n\n# select hyperparameter ----\n#show_best(bag_rs) # showing\nselect_best(bag_rs) # what we'll input\n\n# A tibble: 1 × 3\n  cost_complexity min_n .config              \n            &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;                \n1      0.00000316    11 Preprocessor1_Model08\n\n# finalize the model specification ----\nfinal_bag &lt;- finalize_workflow(wf_bag_tune, select_best(bag_rs))\n#final_bag\n\n# final fitting ----\nfinal_bag_fit &lt;- fit(final_bag, data = tracks_train) \n\n# last_fit() fit on the training data but then also evaluates on the testing data\nfinal_bag_result &lt;- last_fit(final_bag, tracks_split)\n\n# testing predictions and metrics ----\nbag_data &lt;- predict(final_bag_fit, tracks_test) %&gt;% #get prediction probabilities for test \n  bind_cols(tracks_test) %&gt;%  #bind to testing column\n  mutate(name = as.factor(name))\n\n#final_bag_result$.predictions \n\n# report final metrics ----\nfinal_bag_result$.metrics\n\n[[1]]\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.7   Preprocessor1_Model1\n2 roc_auc  binary         0.756 Preprocessor1_Model1"
  },
  {
    "objectID": "projects/2024-04-13-spotify-predictions/index.html#random-forest",
    "href": "projects/2024-04-13-spotify-predictions/index.html#random-forest",
    "title": "Who’s on AUX? Using machine learning to predict whose Spotify playlist a song belongs to",
    "section": "Random Forest",
    "text": "Random Forest\nFinally, I am going to be building a random forest model where I tune the number of trees and the number of predictors that will be randomly sampled at each split.\n\n# random forest ----\nrf_model &lt;- rand_forest(mtry = tune(),\n                  trees = tune()) %&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"classification\")\n\nContain the model and recipe in a workflow and grid tuning.\n\n# workflow ----\nrf_workflow &lt;- workflow() %&gt;%\n  add_model(rf_model) %&gt;%\n  add_recipe(tracks_recipe)\n\n# parameter tuning ----\nrf_cv_tune &lt;- rf_workflow %&gt;%\n  tune_grid(resamples = cv_folds, grid = 10) #use cross validation to tune mtry and trees parameters\n\n#get metrics from tuning cv to pick best model ----\n#collect_metrics(rf_cv_tune) \n\n#plot cv results for parameter tuning ----\nautoplot(rf_cv_tune) + \n  theme_bw()\n\n\n\n\nFinalize the workflow, fit, and predict.\n\n# finalize workflow ----\nrf_best &lt;- show_best(rf_cv_tune, n = 1, metric = \"roc_auc\") #get metrics for best random forest model\nrf_best\n\n# A tibble: 1 × 8\n   mtry trees .metric .estimator  mean     n std_err .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n1     4  1889 roc_auc binary     0.732    10  0.0332 Preprocessor1_Model04\n\nrf_final &lt;- finalize_workflow(rf_workflow,\n                              select_best(rf_cv_tune, metric = \"roc_auc\"))\n\n# model fitting ----\ntrain_fit_rf &lt;- fit(rf_final, tracks_train) #fit the KNN model to the training set\n#train_fit_rf\n\n# prediction probabilities ----\ntest_predict_rf &lt;- predict(train_fit_rf, tracks_test) %&gt;% #get prediction probabilities for test \n  bind_cols(tracks_test) %&gt;%  #bind to testing column\n  mutate(name = as.factor(name))\n\ntest_predict2_rf &lt;- predict(train_fit_rf, tracks_test, type = \"prob\") %&gt;% #get testing prediction\n  bind_cols(tracks_test) %&gt;%  #bind to testing column\n  mutate(name = as.factor(name))\n\n# model metrics and evaluation\n#accuracy(test_predict_rf, truth = name, estimate = .pred_class) #get accuracy of testing prediction\n\nrf_final_result &lt;- last_fit(rf_final, tracks_split)\n\n# testing predictions and metrics ----\n#rf_final_result$.predictions \nrf_predict_data &lt;- as.data.frame(rf_final_result$.predictions) %&gt;%\n  bind_cols(tracks_test)\n\nrf_final_result$.metrics\n\n[[1]]\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.68  Preprocessor1_Model1\n2 roc_auc  binary         0.769 Preprocessor1_Model1\n\n# roc auc curve\ntest_roc_auc_rf &lt;- roc_curve(test_predict2_rf, name, .pred_anna)"
  },
  {
    "objectID": "projects/2023-11-10-phytophthora/index.html",
    "href": "projects/2023-11-10-phytophthora/index.html",
    "title": "Phytophthora presence in Southern Maryland coastal soils",
    "section": "",
    "text": "Sea level rise is changing the ecology and disease dynamics in coastal forests due to frequent flooding and the increased presence of salinity in the soil. The oomycete Phytophthora spp. is responsible for many plant diseases that have had significant environmental and economic consequences (Klinkowski 1970). Recently, invasive P. ramorum has been detected in Maryland, raising concerns about the health of native coastal flora, particularly under climate change (Maryland Department of Agriculture 2017).\n\n\n\n\n\n\nPipetting PARPH media onto petri dishes to prepare for oomycete plating.\n\n\n\nIncreased salinity in soil imposes similar physiological stress as drought does in native plants (Sanogo 2004). Therefore, I explored whether seawater intrusion would promote higher abundances of Phytophthora spp. in coastal soils of Southern Maryland due to potentially having higher plant infections caused by salinity stress."
  },
  {
    "objectID": "projects/2023-11-10-phytophthora/index.html#project-overview",
    "href": "projects/2023-11-10-phytophthora/index.html#project-overview",
    "title": "Phytophthora presence in Southern Maryland coastal soils",
    "section": "",
    "text": "Sea level rise is changing the ecology and disease dynamics in coastal forests due to frequent flooding and the increased presence of salinity in the soil. The oomycete Phytophthora spp. is responsible for many plant diseases that have had significant environmental and economic consequences (Klinkowski 1970). Recently, invasive P. ramorum has been detected in Maryland, raising concerns about the health of native coastal flora, particularly under climate change (Maryland Department of Agriculture 2017).\n\n\n\n\n\n\nPipetting PARPH media onto petri dishes to prepare for oomycete plating.\n\n\n\nIncreased salinity in soil imposes similar physiological stress as drought does in native plants (Sanogo 2004). Therefore, I explored whether seawater intrusion would promote higher abundances of Phytophthora spp. in coastal soils of Southern Maryland due to potentially having higher plant infections caused by salinity stress."
  },
  {
    "objectID": "projects/2023-11-10-phytophthora/index.html#soil-collection",
    "href": "projects/2023-11-10-phytophthora/index.html#soil-collection",
    "title": "Phytophthora presence in Southern Maryland coastal soils",
    "section": "Soil Collection",
    "text": "Soil Collection\nSoil sampling was performed by Jordan Manns and Mel Byrne for their research in Dr. Torres-Martínez's lab. The samples were collected from four different sites across a natural salinity gradient on the Potomac River at two different times of the year. One collection was performed in spring when Phytophthora spp. is likely to be more active, and at the end of summer when hurricane season starts on the Atlantic coast and there is likely to be increased seawater intrusion.\n\n\n\n\n\nFigure 1: Map of soil collection locations in Southern Maryland and the salinity."
  },
  {
    "objectID": "projects/2023-11-10-phytophthora/index.html#culturing",
    "href": "projects/2023-11-10-phytophthora/index.html#culturing",
    "title": "Phytophthora presence in Southern Maryland coastal soils",
    "section": "Culturing",
    "text": "Culturing\n\n\n\n\n\n\nAgar plug culture of Phytophthora!\n\n\n\nThe abundance of Phytophthora spp. was determined by performing serial dilutions of soil samples, plating them on the highly selective PARPH media, and incubating them at 25ºC. Colonies were counted after 4 days of incubation."
  },
  {
    "objectID": "projects/2023-11-10-phytophthora/index.html#analysis",
    "href": "projects/2023-11-10-phytophthora/index.html#analysis",
    "title": "Phytophthora presence in Southern Maryland coastal soils",
    "section": "Analysis",
    "text": "Analysis\nThe abundance of Phytophthora spp. varied by site depending on the season that the soil was collected. In both seasons, it is hard to tell a clear relationship between salinity and Phytophthora abundance. In the spring and summer, there is the highest abundances at the sites with the lowest salinity, but we also see a relatively high abundance at some higher salinity. These results suggest that seawater intrusion and seasonality could modify patterns of Phytophthora spp abundances in coastal soils of Southern Maryland, but further analyses should be done to make any definite conclusions. One possible approach would be to sample soil from a wider salinity range and in colder months as well.\n\n\n\n\n\nFigure 2: Mean cfu/ml across sites and seasons."
  },
  {
    "objectID": "data-viz.html",
    "href": "data-viz.html",
    "title": "Data Visualizations",
    "section": "",
    "text": "Created for EDS240: Data Visualization and Communication\n\n\nThe results of my undergraduate thesis, presented at the Southern Maryland Marine Science 2022\n\n\nThe results of my NSF REU project at Penn State University, presented at the American Meteorological Society conference 2022"
  },
  {
    "objectID": "projects/2023-12-15-plant-population-prediction/index.html",
    "href": "projects/2023-12-15-plant-population-prediction/index.html",
    "title": "Modeling the influence of photosynthetic rate and ecological threats on plant species population trends",
    "section": "",
    "text": "Climate change and human activity are significant contributors to habitat loss, and therefore threaten many plant populations. Nearly 40% of plant species are threatened worldwide, and even more are predicted to become threatened as effects of climate change and human activity continue (IUCN 2023). Many plant species that are threatened or endangered are not very resilient to conditions outside of their niche, often due to their physiological traits, such as carbon fixation or drought tolerance (Bhadra et al. 2022).\nC4 and CAM plants have a more efficient carbon fixation process and are generally more photosynthetically-efficient than C3 processes (Nobel 1991). Plants with high photosynthetic efficiency are often economically important as crops and more resilient to harsh environments due to their energy conservation (Simkin, López-Calcagno, and Raines 2019).\n \nMade with BioRender                            (Bhadra et al. 2022)\nUnderstanding the drivers of plant population decline by specie can help inform on conservation priority, though it is good to keep in mind that not all plants with a decreasing population trend are classified as threatened. Some may have a decreasing population due to effective management of invasive and destructive species (Byun, Blois, and Brisson 2017).\n\n\n\nThere are many other factors that affect a species’ population trend, but in this project, I am wondering how does a plant species’ photosynthetic rate and ecological threats influence its odds of having a decreasing population? Additionally, can I use this model to find the log-odds of a species with an unknown status having a decreasing population trend?"
  },
  {
    "objectID": "projects/2023-12-15-plant-population-prediction/index.html#motivation",
    "href": "projects/2023-12-15-plant-population-prediction/index.html#motivation",
    "title": "Modeling the influence of photosynthetic rate and ecological threats on plant species population trends",
    "section": "",
    "text": "Climate change and human activity are significant contributors to habitat loss, and therefore threaten many plant populations. Nearly 40% of plant species are threatened worldwide, and even more are predicted to become threatened as effects of climate change and human activity continue (IUCN 2023). Many plant species that are threatened or endangered are not very resilient to conditions outside of their niche, often due to their physiological traits, such as carbon fixation or drought tolerance (Bhadra et al. 2022).\nC4 and CAM plants have a more efficient carbon fixation process and are generally more photosynthetically-efficient than C3 processes (Nobel 1991). Plants with high photosynthetic efficiency are often economically important as crops and more resilient to harsh environments due to their energy conservation (Simkin, López-Calcagno, and Raines 2019).\n \nMade with BioRender                            (Bhadra et al. 2022)\nUnderstanding the drivers of plant population decline by specie can help inform on conservation priority, though it is good to keep in mind that not all plants with a decreasing population trend are classified as threatened. Some may have a decreasing population due to effective management of invasive and destructive species (Byun, Blois, and Brisson 2017)."
  },
  {
    "objectID": "projects/2023-12-15-plant-population-prediction/index.html#question",
    "href": "projects/2023-12-15-plant-population-prediction/index.html#question",
    "title": "Modeling the influence of photosynthetic rate and ecological threats on plant species population trends",
    "section": "",
    "text": "There are many other factors that affect a species’ population trend, but in this project, I am wondering how does a plant species’ photosynthetic rate and ecological threats influence its odds of having a decreasing population? Additionally, can I use this model to find the log-odds of a species with an unknown status having a decreasing population trend?"
  },
  {
    "objectID": "projects/2023-12-15-plant-population-prediction/index.html#data-preparation",
    "href": "projects/2023-12-15-plant-population-prediction/index.html#data-preparation",
    "title": "Modeling the influence of photosynthetic rate and ecological threats on plant species population trends",
    "section": "Data Preparation",
    "text": "Data Preparation\nData was prepared in a separate data_fetch.R script. Data from BIEN was cleaned and joined with data from the IUCN Red List entries for species in the kingdom Plantae. Species that had an increasing or stable population trend were assigned a binary variable of 0 and those who had a decreasing population trend were assigned a binary variable of 1.\nsource(file.path(\"data_fetch.R\"))"
  },
  {
    "objectID": "projects/2023-12-15-plant-population-prediction/index.html#data-exploration",
    "href": "projects/2023-12-15-plant-population-prediction/index.html#data-exploration",
    "title": "Modeling the influence of photosynthetic rate and ecological threats on plant species population trends",
    "section": "Data Exploration",
    "text": "Data Exploration\nBefore starting any statistical analysis, we should take a look at the data.\n\n\nCode\nggplot(join, aes(x = avg_photo)) +\n  geom_histogram(fill = \"#94a699\", color = \"black\") +\n  theme_linedraw() +\n  labs(x = \"Avg. Photosynthetic Rate per Leaf Area (Âµmol m-2 s-1)\",\n       title = \"Distribution of photosynthetic rate\") +\n  theme(plot.background = element_rect(color = \"#FDFBF7\",\n                                       fill = \"#FDFBF7\"),\n        panel.background = element_rect(fill = \"#FDFBF7\"))\n\n\n\n\n\n\n\nCode\nggplot(data = join, aes(x = avg_photo, y = pop_trend)) + \n  geom_jitter(width = 0, height = 0.05, alpha = 0.7, color = \"#94a699\") +\n  theme_linedraw() +\n  scale_y_discrete(limits = c(\"Stable_Inc\", \"Decreasing\")) +\n  labs(x = \"Avg. Photosynthetic Rate per Leaf Area (Âµmol m-2 s-1)\", \n       y = \"Population Trend\", \n       title = \"Photosynthetic rate by species population trend\") +\n  theme(plot.background = element_rect(color = \"#FDFBF7\",\n                                       fill = \"#FDFBF7\"),\n        panel.background = element_rect(fill = \"#FDFBF7\"))\n\n\n\n\n\n\n\nCode\nclim_plot &lt;- ggplot(clim_human_res, aes(x = climate_threatened)) +\n  geom_bar(width = 0.5, fill = \"#94a699\", color = \"black\") +\n  theme_linedraw() +\n  labs(x = \"Climate threatened?\") +\n  theme(plot.background = element_rect(color = \"#FDFBF7\",\n                                       fill = \"#FDFBF7\"),\n        panel.background = element_rect(fill = \"#FDFBF7\"))\n\nhuman_plot &lt;- ggplot(clim_human_res, aes(x = human_threatened)) +\n  geom_bar(width = 0.5, fill = \"#94a699\", color = \"black\") +\n  theme_linedraw() +\n  labs(x = \"Human threatened?\", y = \"\") +\n  theme(plot.background = element_rect(color = \"#FDFBF7\",\n                                       fill = \"#FDFBF7\"),\n        panel.background = element_rect(fill = \"#FDFBF7\"))\n\nclim_plot + human_plot + plot_annotation(theme = theme(plot.background = element_rect(color = \"#FDFBF7\",\n                                       fill = \"#FDFBF7\")),\n                                       title = \"Counts for climate threatened and human threated species\")"
  },
  {
    "objectID": "projects/2023-12-15-plant-population-prediction/index.html#logistic-regression",
    "href": "projects/2023-12-15-plant-population-prediction/index.html#logistic-regression",
    "title": "Modeling the influence of photosynthetic rate and ecological threats on plant species population trends",
    "section": "Logistic Regression",
    "text": "Logistic Regression\nTo begin, I want to run a logistic regression on just photosynthetic rate and population trend before incorporating any other variables.\n\\[\n\\operatorname{logit}(p)=\\log \\left(\\frac{p}{1-p}\\right)=\\beta_0+\\beta_1  (Photosynthetic Rate)  +\\varepsilon\n\\]\n\n\nCode\n# binary resp glm plot\nggplot(join, aes(x = avg_photo, y = pop_trend_binary)) + \n  geom_jitter(width = 0, height = 0.05, alpha = 0.8, color = \"#94a699\") +\n  geom_smooth(method = \"glm\", se = FALSE, color = \"#223a2b\", \n              method.args = list(family = \"binomial\"),\n              size = 1.5) +\n  theme_linedraw() +\n  labs(x = \"Avg. Photosynthetic Rate per Leaf Area (Âµmol m-2 s-1)\", \n       y = \"Has Decreasing Population Trend\",\n       title = \"Logistic regression for photosynthetic rate and population trend\") +\n  theme(plot.background = element_rect(color = \"#FDFBF7\",\n                                       fill = \"#FDFBF7\"),\n        panel.background = element_rect(fill = \"#FDFBF7\"))\n\n\n\n\n\n\n\nCode\n# model\nmod_photo &lt;- glm(pop_trend_binary ~ avg_photo, \n                  data = join, \n                  family = \"binomial\") # binomial dist; prob of 1 and 0 over many trials\n\n\n\n\n\nLogisitc Regression Model Results for Photosynthetic Rate\n\n\n \nlog Probability of Decreasing Population\n\n\nPredictors\nLog-Odds\nCI\np-value\n\n\nIntercept\n-0.464 **\n-0.907 – -0.016\n0.041\n\n\nAvg. Photosynthetic Rate (Âµmol m-2 s-1)\n-0.089 ***\n-0.133 – -0.048\n&lt;0.001\n\n\nObservations\n609\n\n\n* p&lt;0.1   ** p&lt;0.05   *** p&lt;0.01\n\n\n\n\n\n\n\nThis model tells us:\nA 1 Âµmol m-2 s-1 increase indicates a 0.089 decrease in probability of having a decreasing population trend.\n\\[\n\\operatorname{logit}(\\hat p)=\\log \\left(\\frac{\\hat p}{1-\\hat p}\\right)=-0.464-0.089 x\n\\]\n\nOdds Ratio\nBy how much does the model predict that the odds of having a decreasing population will change with each additional unit in photosynthetic rate?\n\\[\n\\operatorname{odds}(\\hat{p})=\\frac{\\hat{p}}{1-\\hat{p}}=\\exp \\left(\\hat{\\beta}_0+\\hat{\\beta}_1 \\cdot Photosynthetic Rate\\right)\n\\]\n\n\nCode\nexp(mod_photo$coefficients[2])\n\n\navg_photo \n0.9146572 \n\n\nThe model estimates that one additional unit in photosynthetic rate is associated with a change in the odds ratio of \\(e^{-0.089} = 0.915\\), or a 8.9% decrease in the odds of having a decreasing population.\n\n\nCode\n# compute odds hat var\nphoto_fitted &lt;- mod_photo %&gt;%\n  augment(type.predict = \"response\") %&gt;%\n  mutate(y_hat = .fitted) %&gt;%\n  mutate(odds_hat = y_hat / (1 - y_hat)) # y_hat is p\n\n# plot\nggplot(photo_fitted, aes(x = avg_photo, y = odds_hat)) +\n  geom_point(size = 2.5, color = \"#94a699\", alpha = 0.7) +\n  geom_line(color = \"#223a2b\") + \n  scale_y_continuous() +\n  labs(x = \"Avg. Photosynthetic Rate (Âµmol m-2 s-1)\",\n       y = \"Log-odds of having a decreasing population\",\n       title = \"Log-odds of having a decreasing population trend by photosynthetic rate\") +\n  theme_linedraw() +\n  theme(plot.background = element_rect(color = \"#FDFBF7\",\n                                       fill = \"#FDFBF7\"),\n        panel.background = element_rect(fill = \"#FDFBF7\"))\n\n\n\n\n\nAdditionally, we can visually see this relationship between the odds ratio and photosynthetic rate. As photosynthetic rate increases, the log-odds of having a decreasing population decreases."
  },
  {
    "objectID": "projects/2023-12-15-plant-population-prediction/index.html#full-logistic-model",
    "href": "projects/2023-12-15-plant-population-prediction/index.html#full-logistic-model",
    "title": "Modeling the influence of photosynthetic rate and ecological threats on plant species population trends",
    "section": "Full Logistic Model",
    "text": "Full Logistic Model\nThis first logistic model only considered photosynthetic rate, but now we want to add in if the species is threatened by climate change or human activity, since both of these historically have contributed to plant species becoming threatened.\n\\[\\operatorname{logit}(p)=\\log \\left(\\frac{p}{1-p}\\right)=\\beta_0+\\beta_1  (Photosynthetic Rate) + \\beta_2  (Climate) + \\beta_3  (Human) +\\varepsilon \\]\n\n\nCode\nmod &lt;- glm(pop_trend_binary ~ avg_photo + climate_threatened + human_threatened,\n           data = clim_human_res,\n           family = \"binomial\")\n\nexp(coef(mod))\n\n\n          (Intercept)             avg_photo climate_threatenedyes \n            0.6314813             0.8959289             4.2980568 \n  human_threatenedyes \n            2.5251016 \n\n\nCode\nmod$coefficients[2] # B1\n\n\n avg_photo \n-0.1098942 \n\n\n\n\n\nLogisitc Regression Model Results for Photosynthetic Rate, Climate Threatened, and Human Threatened\n\n\n \nlog Threat Pobability\n\n\nPredictors\nLog-Odds\nCI\np-value\n\n\nIntercept\n-0.460 *\n-0.922 – 0.004\n0.051\n\n\nAverage Photosyntheitc Rate (Âµmol m-2 s-1)\n-0.110 ***\n-0.158 – -0.065\n&lt;0.001\n\n\nClimate Threatened\n1.458 ***\n0.665 – 2.237\n&lt;0.001\n\n\nHuman Threatened\n0.926 \n-0.299 – 2.210\n0.145\n\n\nObservations\n609\n\n\n* p&lt;0.1   ** p&lt;0.05   *** p&lt;0.01\n\n\n\n\n\n\n\nFrom this model we can conclude that plants threatened by climate factors have their odds of having a decreasing population increase by a factor of 4.29, while those threatened by human factors have their odds increase by a factor of 2.52.\nWe can also see that photosynthetic rate does still have an effect on population trend. Based on this model, the odds of having a decreasing population trend fall by about 11% for each unit increase in photosynthetic rate."
  },
  {
    "objectID": "projects/2023-12-10-research-ethics-kaza/index.html",
    "href": "projects/2023-12-10-research-ethics-kaza/index.html",
    "title": "Ethical Challenges in Investigating Human-Elephant Conflict",
    "section": "",
    "text": "In 2023 I started as an Arnhold Environmental Graduate Research Fellow in collaboration with the emLab at UCSB and Conservation International SPARC. During my interview and subsequent on boarding process, I learned that the research would be focused on areas of Southern Africa, mainly the KAZA region. For those unfamiliar with the term KAZA TFCA (as I was initially), it stands for Kavango–Zambezi Transfrontier Conservation Area, which is one of the largest landscape conservation areas in the world, spanning Angola, Zambia, Zimbabwe, Botswana, and Namibia (WWF 2016). It’s a beautiful, diverse area that, focuses on sustainable ecosystem management, attracts many tourists, and serves as a hub for various research initiatives.\n\n\n\n\n\nMap of the KAZA TCFA (WWFNamibia 2015).\nBroadly, our research questions revolve around the effects of climate change on wildlife corridors, human intrusion into these corridors, and the subsequent impacts on human-elephant conflict. Throughout my data analysis and literature review, I’ve been contemplating the following questions: In what ways can we ensure that our research is relevant and beneficial for the communities we’re studying and using data from? What factors should we keep in mind when conducting and reporting research on communities that we have no personal connections to?\n\n\n\n\n\nElephants in KAZA (WWF 2016).\nTo dive into these questions, I am drawing inspiration from AI Blindspot (Calderon et al. 2019), which was developed during the Berkman Klein Center and MIT Media Lab’s 2019 Assembly program. This guide was developed with AI data and models in mind, but many of the questions and concepts apply to data and research ethics in general. The authors lay out the potential sources of bias & oversight, or “blind spots”, in four sections: Planning, Building, Deploying, and Monitoring."
  },
  {
    "objectID": "projects/2023-12-10-research-ethics-kaza/index.html#fa-ruler-combined-planning",
    "href": "projects/2023-12-10-research-ethics-kaza/index.html#fa-ruler-combined-planning",
    "title": "Ethical Challenges in Investigating Human-Elephant Conflict",
    "section": " Planning",
    "text": "Planning\nThis initial section guides us to assess the alignment of our research methods with expected outcomes and also addresses potential vulnerabilities and issues related to the safety of data.\n\nClearly articulate the problem and outcome you are optimizing for.\nThe rise in human-elephant conflict in KAZA is believed to stem from the impacts of climate change on habitat suitability and human encroachment on wildlife corridors (Kamwi et al. 2015). In this project, we aim to analyze how human activity has altered land cover in wildlife corridors over time and how human presence in relation to the corridors is predicted to change in the future based on current trends. Additionally, we are exploring how the locations of human-elephant conflicts relate to the location of corridors, and what seasonal or climactic variables have the most influence on conflict rates. Results from this research can help inform local communities about potential future dangers to them from elephants, and how their activities are influencing these conflicts.\n\n\nHave you engaged with affected communities? Subject matter experts?\nYes, we have collaborators at the University of Namibia who have been engaging in this field of research for a while. They have conducted village interviews to collect data on human-wildlife conflicts.\n\n\nAbusability\nWhile this research can help further our understanding of human-elephant conflicts and their developments, it’s critical to acknowledge the dual-edged nature of reporting this information. It is possible that government officials could use these findings to implement changes in community activities, potentially restricting access to essential resources. This raises concerns about the responsible use of this data and research outcomes.\n\n\nPrivacy\nPersonal information from the conflict interviews has not been recorded, so people can retain anonymity. When it comes to publishing wildlife research, a major concern revolves around determining who has access to the data due to the potential for malicious use. A majority of elephant data cannot be made publicly available since there are poachers who will use the data for ill intentions."
  },
  {
    "objectID": "projects/2023-12-10-research-ethics-kaza/index.html#fa-compass-drafting-building",
    "href": "projects/2023-12-10-research-ethics-kaza/index.html#fa-compass-drafting-building",
    "title": "Ethical Challenges in Investigating Human-Elephant Conflict",
    "section": " Building",
    "text": "Building\nThis second section asks questions that expand on how local communities are impacted by our research.\n\nIs this research accessible to those who are the most affected by it? Do they trust it?\nWhile we do have conflict surveys, I think it would be beneficial to consider conducting a follow-up survey in the same villages once the project results are available. This additional survey would help to gauge the level of trust in our analyses—assessing whether the community understands the analysis process, cares about the results, and finds them consistent with their personal observations of human-elephant conflicts. This approach adds an additional layer of community engagement and ensures that our research is not only informative but incorperates the experiences of those directly impacted.\n\n\nHow rigid should we be when developing our future projections of human-elephant conflict?\nVarious model developments may yield projections that are either lower than actual future impacts, potentially providing a false sense of comfort, or significantly higher than actual future impacts, leading to unnecessary anxiety or harsher regulations."
  },
  {
    "objectID": "projects/2023-12-10-research-ethics-kaza/index.html#fa-network-wired-deploying",
    "href": "projects/2023-12-10-research-ethics-kaza/index.html#fa-network-wired-deploying",
    "title": "Ethical Challenges in Investigating Human-Elephant Conflict",
    "section": " Deploying",
    "text": "Deploying\nThe third section focuses on the actual performance of AI models and how changes in data might not be accounted for. I have modified and compiled their questions in this section to think about indigenous data and what we might consider to be “non-traditional” data.\n\nHow might our model not accurately reflect people’s local knowledge and personal experiences with changes in human-elephant conflict?\nWe are assuming that increased rates of conflict are due to human encroachment on corridors, but what is not considered in our data is the specific ways and reasons that people’s movement is changing. We have reports of human-elephant conflict, but not the specific information on how the conflict came about. Have increases in reports of conflict occurred because there has been an actual increase in conflict events, or has conflict reporting and recording become common? Are changes in human activity influenced by factors of climate change as much as elephant activity is? We cannot reliably integrate lived experiences into spatial suitability and resistance modeling, but this data can and should be considered when making conclusions from the modeling."
  },
  {
    "objectID": "projects/2023-12-10-research-ethics-kaza/index.html#fa-magnifying-glass-oversight",
    "href": "projects/2023-12-10-research-ethics-kaza/index.html#fa-magnifying-glass-oversight",
    "title": "Ethical Challenges in Investigating Human-Elephant Conflict",
    "section": " Oversight",
    "text": "Oversight\nFinally, we must continue to address oversights in our modeling. Continuing from the ideas in the previous section, it is imperative that we work closely with our local collaborators and gain further insight into how our research can benefit the local communities.\n\nIn what ways can we improve our communication with those in affected communities and those who have more expertise in the area?\nCurrently, we are meeting with our collaborators in Namibia less often than we should be, but this is more of an issue of conflicting schedules and time differences. We are also still figuring out how to best integrate our research interests with theirs, but we have made it clear to them that if any of our research directions do not align with their priorities, we will not continue to pursue them. A significant portion of the data necessary for our research comes directly from our collaborators. We are grateful that they trust us with this data and we will only be using the data how they see fit."
  },
  {
    "objectID": "projects/2023-12-05-fire-aqi/index.html",
    "href": "projects/2023-12-05-fire-aqi/index.html",
    "title": "Environmental impact and air quality analysis of the 2017 Thomas Fire in Santa Barbara County",
    "section": "",
    "text": "Link to project repository: https://github.com/shmuir/california-fire-AQI"
  },
  {
    "objectID": "projects/2023-12-05-fire-aqi/index.html#highlights-of-analysis",
    "href": "projects/2023-12-05-fire-aqi/index.html#highlights-of-analysis",
    "title": "Environmental impact and air quality analysis of the 2017 Thomas Fire in Santa Barbara County",
    "section": "Highlights of Analysis",
    "text": "Highlights of Analysis\nIn this blog post I will be:\n\nFetching and cleaning raster and tabular data\nVisualizing the extent of the burn areas from the Thomas Fire in Santa Barbara County in 2017\nAnalyzing the change in air quality in Santa Barbara County across 2017-2018."
  },
  {
    "objectID": "projects/2023-12-05-fire-aqi/index.html#data-sources",
    "href": "projects/2023-12-05-fire-aqi/index.html#data-sources",
    "title": "Environmental impact and air quality analysis of the 2017 Thomas Fire in Santa Barbara County",
    "section": "Data Sources",
    "text": "Data Sources\nThe Thomas fire shapefile was obtained from California State Geoportal.\nSanta Barbara landsat data was accessed and pre-processed in the Microsoft Planetary Computer to remove data outside land and coarsen the spatial resolution (Landsat Collection in MPC).\nThe Air Quality Index (AQI) was obtained from the US Environmental Protection Agency."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects & Blog",
    "section": "",
    "text": "Who’s on AUX? Using machine learning to predict whose Spotify playlist a song belongs to\n\n\n\nML\n\n\nR\n\n\nMEDS\n\n\n\nBuilding my ML skills through a fun musical project\n\n\n\nSam Muir\n\n\nApr 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModeling the influence of photosynthetic rate and ecological threats on plant species population trends\n\n\n\nPlants\n\n\nClimate\n\n\nR\n\n\nMEDS\n\n\n\nPredicting population trends for those with an unknown status\n\n\n\nSam Muir\n\n\nDec 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nEthical Challenges in Investigating Human-Elephant Conflict\n\n\n\nMEDS\n\n\nEJ\n\n\n\nConsiderations of Research in KAZA with Insights from AI Blindspot\n\n\n\nSam Muir\n\n\nDec 10, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nEnvironmental impact and air quality analysis of the 2017 Thomas Fire in Santa Barbara County\n\n\n\nGIS\n\n\nMEDS\n\n\nPython\n\n\n\nVisualizing the burn area and change in air quality index\n\n\n\nSam Muir\n\n\nDec 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentifying power outages in Houston, TX from February 2021 storms\n\n\n\nGIS\n\n\nMEDS\n\n\nR\n\n\n\nCreated for EDS223: Geospatial Analysis for the Masters of Environmental Data Science program at UCSB\n\n\n\nSam Muir\n\n\nNov 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhytophthora presence in Southern Maryland coastal soils\n\n\n\nPlants\n\n\nEcology\n\n\nCoastal\n\n\n\nAnalyzing the influence of seawater intrusion on oomycete abundance\n\n\n\nSam Muir\n\n\nNov 10, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "gallery.html",
    "href": "gallery.html",
    "title": "Data Visualizations & Posters",
    "section": "",
    "text": "Click on any of the images to get a closer look!\n\n\n    \n\n\n\n×"
  },
  {
    "objectID": "my_env/lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html",
    "href": "my_env/lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html",
    "title": "Authors",
    "section": "",
    "text": "pyqode.qt: Colin Duquesnoy (@ColinDuquesnoy)\nspyderlib.qt: Pierre Raybaut (@PierreRaybaut)\nqt-helpers: Thomas Robitaille (@astrofrog)\n\n\n\n\n\nDaniel Althviz (@dalthviz)\nCarlos Cordoba (@ccordoba12)\nC.A.M. Gerlach (@CAM-Gerlach)\nSpyder Development Team (Spyder-IDE)\n\n\n\n\n\nThe QtPy Contributors"
  },
  {
    "objectID": "my_env/lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#original-authors",
    "href": "my_env/lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#original-authors",
    "title": "Authors",
    "section": "",
    "text": "pyqode.qt: Colin Duquesnoy (@ColinDuquesnoy)\nspyderlib.qt: Pierre Raybaut (@PierreRaybaut)\nqt-helpers: Thomas Robitaille (@astrofrog)"
  },
  {
    "objectID": "my_env/lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#current-maintainers",
    "href": "my_env/lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#current-maintainers",
    "title": "Authors",
    "section": "",
    "text": "Daniel Althviz (@dalthviz)\nCarlos Cordoba (@ccordoba12)\nC.A.M. Gerlach (@CAM-Gerlach)\nSpyder Development Team (Spyder-IDE)"
  },
  {
    "objectID": "my_env/lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#contributors",
    "href": "my_env/lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#contributors",
    "title": "Authors",
    "section": "",
    "text": "The QtPy Contributors"
  },
  {
    "objectID": "my_env/lib/python3.11/site-packages/numpy/random/LICENSE.html",
    "href": "my_env/lib/python3.11/site-packages/numpy/random/LICENSE.html",
    "title": "NCSA Open Source License",
    "section": "",
    "text": "This software is dual-licensed under the The University of Illinois/NCSA Open Source License (NCSA) and The 3-Clause BSD License\n\nNCSA Open Source License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nDeveloped by: Kevin Sheppard (kevin.sheppard@economics.ox.ac.uk, kevin.k.sheppard@gmail.com) http://www.kevinsheppard.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal with the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimers.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimers in the documentation and/or other materials provided with the distribution.\nNeither the names of Kevin Sheppard, nor the names of any contributors may be used to endorse or promote products derived from this Software without specific prior written permission.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH THE SOFTWARE.\n\n\n3-Clause BSD License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nComponents\nMany parts of this module have been derived from original sources, often the algorithm’s designer. Component licenses are located with the component code."
  },
  {
    "objectID": "my_env/lib/python3.11/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "href": "my_env/lib/python3.11/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "title": "UAT for NbAgg backend.",
    "section": "",
    "text": "from imp import reload\nThe first line simply reloads matplotlib, uses the nbagg backend and then reloads the backend, just to ensure we have the latest modification to the backend code. Note: The underlying JavaScript will not be updated by this process, so a refresh of the browser after clearing the output and saving is necessary to clear everything fully.\nimport matplotlib\nreload(matplotlib)\n\nmatplotlib.use('nbagg')\n\nimport matplotlib.backends.backend_nbagg\nreload(matplotlib.backends.backend_nbagg)"
  },
  {
    "objectID": "my_env/lib/python3.11/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "href": "my_env/lib/python3.11/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "title": "UAT for NbAgg backend.",
    "section": "UAT 13 - Animation",
    "text": "UAT 13 - Animation\nThe following should generate an animated line:\n\nimport matplotlib.animation as animation\nimport numpy as np\n\nfig, ax = plt.subplots()\n\nx = np.arange(0, 2*np.pi, 0.01)        # x-array\nline, = ax.plot(x, np.sin(x))\n\ndef animate(i):\n    line.set_ydata(np.sin(x+i/10.0))  # update the data\n    return line,\n\n#Init only required for blitting to give a clean slate.\ndef init():\n    line.set_ydata(np.ma.array(x, mask=True))\n    return line,\n\nani = animation.FuncAnimation(fig, animate, np.arange(1, 200), init_func=init,\n                              interval=100., blit=True)\nplt.show()\n\n\nUAT 14 - Keyboard shortcuts in IPython after close of figure\nAfter closing the previous figure (with the close button above the figure) the IPython keyboard shortcuts should still function.\n\n\nUAT 15 - Figure face colours\nThe nbagg honours all colours apart from that of the figure.patch. The two plots below should produce a figure with a red background. There should be no yellow figure.\n\nimport matplotlib\nmatplotlib.rcParams.update({'figure.facecolor': 'red',\n                            'savefig.facecolor': 'yellow'})\nplt.figure()\nplt.plot([3, 2, 1])\n\nplt.show()\n\n\n\nUAT 16 - Events\nPressing any keyboard key or mouse button (or scrolling) should cycle the line while the figure has focus. The figure should have focus by default when it is created and re-gain it by clicking on the canvas. Clicking anywhere outside of the figure should release focus, but moving the mouse out of the figure should not release focus.\n\nimport itertools\nfig, ax = plt.subplots()\nx = np.linspace(0,10,10000)\ny = np.sin(x)\nln, = ax.plot(x,y)\nevt = []\ncolors = iter(itertools.cycle(['r', 'g', 'b', 'k', 'c']))\ndef on_event(event):\n    if event.name.startswith('key'):\n        fig.suptitle('%s: %s' % (event.name, event.key))\n    elif event.name == 'scroll_event':\n        fig.suptitle('%s: %s' % (event.name, event.step))\n    else:\n        fig.suptitle('%s: %s' % (event.name, event.button))\n    evt.append(event)\n    ln.set_color(next(colors))\n    fig.canvas.draw()\n    fig.canvas.draw_idle()\n\nfig.canvas.mpl_connect('button_press_event', on_event)\nfig.canvas.mpl_connect('button_release_event', on_event)\nfig.canvas.mpl_connect('scroll_event', on_event)\nfig.canvas.mpl_connect('key_press_event', on_event)\nfig.canvas.mpl_connect('key_release_event', on_event)\n\nplt.show()\n\n\n\nUAT 17 - Timers\nSingle-shot timers follow a completely different code path in the nbagg backend than regular timers (such as those used in the animation example above.) The next set of tests ensures that both “regular” and “single-shot” timers work properly.\nThe following should show a simple clock that updates twice a second:\n\nimport time\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\n\ndef update(text):\n    text.set(text=time.ctime())\n    text.axes.figure.canvas.draw()\n    \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\ntimer.start()\nplt.show()\n\nHowever, the following should only update once and then stop:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center') \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\n\nplt.show()\n\nAnd the next two examples should never show any visible text at all:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\n\nUAT 18 - stopping figure when removed from DOM\nWhen the div that contains from the figure is removed from the DOM the figure should shut down it’s comm, and if the python-side figure has no more active comms, it should destroy the figure. Repeatedly running the cell below should always have the same figure number\n\nfig, ax = plt.subplots()\nax.plot(range(5))\nplt.show()\n\nRunning the cell below will re-show the figure. After this, re-running the cell above should result in a new figure number.\n\nfig.canvas.manager.reshow()\n\n\n\nUAT 19 - Blitting\nClicking on the figure should plot a green horizontal line moving up the axes.\n\nimport itertools\n\ncnt = itertools.count()\nbg = None\n\ndef onclick_handle(event):\n    \"\"\"Should draw elevating green line on each mouse click\"\"\"\n    global bg\n    if bg is None:\n        bg = ax.figure.canvas.copy_from_bbox(ax.bbox) \n    ax.figure.canvas.restore_region(bg)\n\n    cur_y = (next(cnt) % 10) * 0.1\n    ln.set_ydata([cur_y, cur_y])\n    ax.draw_artist(ln)\n    ax.figure.canvas.blit(ax.bbox)\n\nfig, ax = plt.subplots()\nax.plot([0, 1], [0, 1], 'r')\nln, = ax.plot([0, 1], [0, 0], 'g', animated=True)\nplt.show()\nax.figure.canvas.draw()\n\nax.figure.canvas.mpl_connect('button_press_event', onclick_handle)"
  }
]